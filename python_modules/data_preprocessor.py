#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
í”¼ë“œë°± ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¤‘ë³µ ì œê±°

ëª©ì :
1. ì¤‘ë³µëœ í”¼ë“œë°± ìŒ ì œê±°
2. ë°ì´í„° í’ˆì§ˆ í–¥ìƒ
3. ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
"""

import os
import json
import numpy as np
from pathlib import Path
from datetime import datetime
import hashlib

class FeedbackDataPreprocessor:
    def __init__(self, input_dir, output_dir):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.all_feedback = []
        self.unique_feedback = []
        self.duplicate_info = []
        
    def create_pair_hash(self, design_a_id, design_b_id, design_a_state, design_b_state):
        """ë””ìì¸ ìŒì˜ ê³ ìœ  í•´ì‹œ ìƒì„±"""
        # IDì™€ ìƒíƒœë¥¼ ì¡°í•©í•˜ì—¬ ê³ ìœ ì„± í™•ë³´
        pair_data = {
            'ids': tuple(sorted([design_a_id, design_b_id])),
            'states': tuple(sorted([tuple(design_a_state), tuple(design_b_state)]))
        }
        
        # í•´ì‹œ ìƒì„±
        pair_str = json.dumps(pair_data, sort_keys=True)
        return hashlib.md5(pair_str.encode()).hexdigest()
    
    def load_and_process_feedback(self):
        """í”¼ë“œë°± ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬"""
        json_files = list(self.input_dir.glob('*.json'))
        print(f"ğŸ“‚ {len(json_files)}ê°œì˜ í”¼ë“œë°± íŒŒì¼ ë°œê²¬")
        
        seen_hashes = {}
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # í•´ì‹œ ìƒì„±
                pair_hash = self.create_pair_hash(
                    data['design_a_id'],
                    data['design_b_id'],
                    data['design_a_state'],
                    data['design_b_state']
                )
                
                # ì¤‘ë³µ ì²´í¬
                if pair_hash in seen_hashes:
                    # ì¤‘ë³µëœ ê²½ìš° - ë™ì¼í•œ ì„ íƒì¸ì§€ í™•ì¸
                    original = seen_hashes[pair_hash]
                    if original['selected_design'] != data['selected_design']:
                        print(f"âš ï¸ ì¶©ëŒí•˜ëŠ” ì„ íƒ ë°œê²¬: {json_file.name}")
                        print(f"   ì›ë³¸: {original['selected_design']}")
                        print(f"   í˜„ì¬: {data['selected_design']}")
                    
                    self.duplicate_info.append({
                        'file': json_file.name,
                        'original_file': original['file'],
                        'hash': pair_hash
                    })
                else:
                    # ìƒˆë¡œìš´ í”¼ë“œë°±
                    seen_hashes[pair_hash] = {
                        'data': data,
                        'file': json_file.name,
                        'selected_design': data['selected_design']
                    }
                    self.unique_feedback.append(data)
                
                self.all_feedback.append(data)
                
            except Exception as e:
                print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {json_file.name} - {e}")
        
        print(f"\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   ì „ì²´ í”¼ë“œë°±: {len(self.all_feedback)}ê°œ")
        print(f"   ê³ ìœ í•œ í”¼ë“œë°±: {len(self.unique_feedback)}ê°œ")
        print(f"   ì¤‘ë³µ ì œê±°ë¨: {len(self.duplicate_info)}ê°œ")
    
    def analyze_unique_data(self):
        """ê³ ìœ  ë°ì´í„° ë¶„ì„"""
        print("\nğŸ” ê³ ìœ  ë°ì´í„° ë¶„ì„")
        print("="*60)
        
        # ì„ í˜¸/ê±°ë¶€ ìƒíƒœ ì¶”ì¶œ
        preferred_states = []
        rejected_states = []
        
        for feedback in self.unique_feedback:
            if feedback['selected_design'] == feedback['design_a_id']:
                preferred_states.append(feedback['design_a_state'])
                rejected_states.append(feedback['design_b_state'])
            else:
                preferred_states.append(feedback['design_b_state'])
                rejected_states.append(feedback['design_a_state'])
        
        preferred_states = np.array(preferred_states)
        rejected_states = np.array(rejected_states)
        
        # íŠ¹ì„±ë³„ ì°¨ì´ ë¶„ì„
        feature_names = ['BCR', 'FAR', 'WinterTime', 'SVR']
        state_diffs = preferred_states - rejected_states
        
        print("\nì„ í˜¸-ê±°ë¶€ ì°¨ì´ ë¶„ì„ (ì¤‘ë³µ ì œê±° í›„):")
        for i, feature in enumerate(feature_names):
            diff_values = state_diffs[:, i]
            print(f"\n{feature}:")
            print(f"  í‰ê·  ì°¨ì´: {diff_values.mean():.4f} (Â±{diff_values.std():.4f})")
            print(f"  ì„ í˜¸ ë°©í–¥: ë†’ìŒ {np.sum(diff_values > 0)}ê°œ ({np.sum(diff_values > 0)/len(diff_values)*100:.1f}%)")
            
            # íš¨ê³¼ í¬ê¸° (Cohen's d)
            cohens_d = diff_values.mean() / diff_values.std() if diff_values.std() > 0 else 0
            print(f"  íš¨ê³¼ í¬ê¸° (Cohen's d): {cohens_d:.3f}")
    
    def save_processed_data(self):
        """ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        # 1. ê³ ìœ  í”¼ë“œë°± ì €ì¥ (ê°œë³„ íŒŒì¼)
        unique_dir = self.output_dir / 'unique_feedback'
        unique_dir.mkdir(exist_ok=True)
        
        for i, feedback in enumerate(self.unique_feedback):
            output_file = unique_dir / f"unique_feedback_{i:04d}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(feedback, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ {len(self.unique_feedback)}ê°œì˜ ê³ ìœ  í”¼ë“œë°± ì €ì¥ë¨: {unique_dir}")
        
        # 2. í†µí•© íŒŒì¼ ì €ì¥ (í•™ìŠµìš©)
        consolidated_file = self.output_dir / 'consolidated_feedback.json'
        with open(consolidated_file, 'w', encoding='utf-8') as f:
            json.dump(self.unique_feedback, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ í†µí•© í”¼ë“œë°± íŒŒì¼ ì €ì¥ë¨: {consolidated_file}")
        
        # 3. ì²˜ë¦¬ ìš”ì•½ ì €ì¥
        summary = {
            'processing_date': datetime.now().isoformat(),
            'total_original': len(self.all_feedback),
            'total_unique': len(self.unique_feedback),
            'duplicates_removed': len(self.duplicate_info),
            'duplicate_ratio': len(self.duplicate_info) / len(self.all_feedback) if self.all_feedback else 0,
            'duplicate_details': self.duplicate_info[:10]  # ì²˜ìŒ 10ê°œë§Œ
        }
        
        summary_file = self.output_dir / 'preprocessing_summary.json'
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ ì „ì²˜ë¦¬ ìš”ì•½ ì €ì¥ë¨: {summary_file}")
    
    def create_train_ready_format(self):
        """í•™ìŠµ ì¤€ë¹„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        train_ready_data = []
        
        for feedback in self.unique_feedback:
            # ì„ í˜¸/ê±°ë¶€ ìƒíƒœ ê²°ì •
            if feedback['selected_design'] == feedback['design_a_id']:
                preferred = feedback['design_a_state']
                rejected = feedback['design_b_state']
            else:
                preferred = feedback['design_b_state']
                rejected = feedback['design_a_state']
            
            train_ready_data.append({
                'preferred_state': preferred,
                'rejected_state': rejected,
                'original_id': feedback['id']
            })
        
        # í•™ìŠµìš© í˜•ì‹ìœ¼ë¡œ ì €ì¥
        train_file = self.output_dir / 'train_ready_feedback.json'
        with open(train_file, 'w', encoding='utf-8') as f:
            json.dump(train_ready_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ¯ í•™ìŠµ ì¤€ë¹„ ë°ì´í„° ì €ì¥ë¨: {train_file}")
        
        return train_file

def main():
    # ê²½ë¡œ ì„¤ì •
    input_dir = r"C:\Users\valen\Desktop\Dev\6. RLHF\data\feedback"
    output_dir = r"C:\Users\valen\Desktop\Dev\6. RLHF\data\processed_feedback"
    
    print("ğŸ”§ í”¼ë“œë°± ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
    print("="*80)
    
    # ì „ì²˜ë¦¬ê¸° ìƒì„±
    preprocessor = FeedbackDataPreprocessor(input_dir, output_dir)
    
    # ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
    preprocessor.load_and_process_feedback()
    
    # ê³ ìœ  ë°ì´í„° ë¶„ì„
    preprocessor.analyze_unique_data()
    
    # ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
    preprocessor.save_processed_data()
    
    # í•™ìŠµ ì¤€ë¹„ í˜•ì‹ ìƒì„±
    train_file = preprocessor.create_train_ready_format()
    
    print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ê°œì„ ëœ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”:")
    print(f'python improved_reward_model_trainer.py --feedback-data "{train_file}" --output-dir "improved_models"')

if __name__ == "__main__":
    main()