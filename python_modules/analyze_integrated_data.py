#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
RLHF ë°ì´í„° í†µí•© ë° ë¶„ì„ ë„êµ¬ (RLHF ìŒëŒ€ë¹„êµìš© ì—…ë°ì´íŠ¸)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” PPO í•™ìŠµ ê²°ê³¼ì™€ ZMQë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ìƒíƒœ/ë³´ìƒ ë°ì´í„°ë¥¼ í†µí•©í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.
ìŒëŒ€ë¹„êµë¥¼ ìœ„í•œ ê¸°ì¤€ì ì„ ì œê³µí•˜ê³ , ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
"""

import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import argparse
import torch
from pathlib import Path
import re
import time
import shutil
import traceback
import uuid

# ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('ggplot')
sns.set(style="whitegrid")

class RLHFDataAnalyzer:
    """
    ê°•í™”í•™ìŠµ ë°ì´í„°ì™€ ì¸ê°„ í”¼ë“œë°± ë°ì´í„°ë¥¼ í†µí•© ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤
    ìŒëŒ€ë¹„êµë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ì— íŠ¹í™”
    """
    
    def __init__(self, state_reward_log_path, model_dir=None, ppo_log_path=None, session_dir=None):
        """
        ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            state_reward_log_path: ZMQë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ìƒíƒœ/ë³´ìƒ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
            model_dir: PPO ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì„ íƒì )
            ppo_log_path: PPO í•™ìŠµ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
            session_dir: ê²°ê³¼ë¬¼ì´ ì €ì¥ë  ì„¸ì…˜ ë””ë ‰í† ë¦¬ (ì„ íƒì )
        """
        self.state_reward_log_path = state_reward_log_path
        self.model_dir = model_dir
        self.ppo_log_path = ppo_log_path
        self.session_dir = session_dir
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.zmq_data = None
        self.ppo_log_data = None
        self.model_info = None
        
        # RLHF ì‹œìŠ¤í…œ ì„¤ì • (í™•ì¥ëœ ìƒíƒœ ê³µê°„)
        self.state_labels = ["BCR", "FAR", "Winter_Sunlight", "SV_Ratio"]
        self.state_dimensions = len(self.state_labels)
        
        # ê±´ì¶• ì„¤ê³„ ì œì•½ ì¡°ê±´
        self.design_constraints = {
            'bcr_limit': 0.70,  # 70% ë¯¸ë§Œ
            'far_min': 2.0,     # 200% ì´ìƒ
            'far_max': 5.0,     # 500% ì´í•˜  
            'sunlight_min': 80000,  # 80k kWh ì´ìƒ
            'sunlight_max': 120000, # 120k kWh ëª©í‘œ
            'svr_optimal': 0.8,     # 0.8 ìµœì 
            'svr_range': [0.6, 1.0] # í—ˆìš© ë²”ìœ„
        }
        
        # ë°ì´í„° ë¡œë“œ
        self._load_zmq_data()
        if ppo_log_path:
            self._load_ppo_log()
        if model_dir:
            self._load_model_info()
    
    def _load_zmq_data(self):
        """ZMQ ìƒíƒœ/ë³´ìƒ ë°ì´í„° ë¡œë“œ (RLHFìš© ê°œì„ )"""
        try:
            print(f"ZMQ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘: {self.state_reward_log_path}")
            
            # íŒŒì¼ ì½ê¸° ë° ì¸ì½”ë”© ì²˜ë¦¬
            with open(self.state_reward_log_path, 'rb') as f:
                binary_content = f.read()
                
            # ì¸ì½”ë”© ì‹œë„
            encodings_to_try = ['utf-8', 'cp949', 'euc-kr', 'latin1']
            content = None
            
            for encoding in encodings_to_try:
                try:
                    content = binary_content.decode(encoding, errors='replace')
                    print(f"íŒŒì¼ì„ '{encoding}' ì¸ì½”ë”©ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                content = binary_content.decode('latin1')
                print(f"ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨. 'latin1'ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            
            # JSON ìˆ˜ì •
            if not content.strip().endswith("]"):
                print("ê²½ê³ : JSON íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ë‹«íˆì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.")
                if content.strip().endswith(","):
                    content = content.rstrip().rstrip(",")
                content += "\n]"
            
            # JSON íŒŒì‹±
            try:
                data = json.loads(content)
            except json.JSONDecodeError as e:
                print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                print("ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ë¼ì¸ë³„ íŒŒì‹±ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                data = self._parse_json_lines(content)
            
            if not data:
                print("ê²½ê³ : ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                self.zmq_data = pd.DataFrame()
                self.zmq_data_filtered = pd.DataFrame()
                return
            
            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ (RLHFìš© ê°œì„ )
            df_list = []
            for entry in data:
                try:
                    # ìƒíƒœ ë° ì•¡ì…˜ ì²˜ë¦¬
                    state_val = entry.get('state', [0.0] * self.state_dimensions)
                    action_val = entry.get('action', [0.0])
                    
                    # ìƒíƒœ ì°¨ì› ê²€ì¦ ë° ì¡°ì •
                    if isinstance(state_val, list):
                        if len(state_val) < self.state_dimensions:
                            # ë¶€ì¡±í•œ ì°¨ì›ì„ 0ìœ¼ë¡œ ì±„ì›€
                            state_val.extend([0.0] * (self.state_dimensions - len(state_val)))
                        elif len(state_val) > self.state_dimensions:
                            # ì´ˆê³¼ ì°¨ì› ì œê±°
                            state_val = state_val[:self.state_dimensions]
                        state_str = ','.join(map(str, state_val))
                    else:
                        state_val = [float(state_val)] + [0.0] * (self.state_dimensions - 1)
                        state_str = ','.join(map(str, state_val))
                    
                    # ì•¡ì…˜ ì²˜ë¦¬
                    if isinstance(action_val, list):
                        action_str = ','.join(map(str, action_val))
                    else:
                        action_str = str(action_val)
                    
                    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                    row = {
                        'timestamp': entry.get('timestamp', 0),
                        'uptime_ms': entry.get('uptime_ms', 0),
                        'state': state_str,
                        'reward': entry.get('reward', 0.0),
                        'action': action_str,
                        'msg_id': entry.get('msg_id', 0),
                        'type': entry.get('type', 'data'),
                        'design_id': f"design_{entry.get('msg_id', 0)}_{int(entry.get('timestamp', 0))}"
                    }
                    
                    # ìƒíƒœ ì°¨ì›ë³„ ê°œë³„ ì—´ ì¶”ê°€
                    for i, label in enumerate(self.state_labels):
                        if i < len(state_val):
                            row[f'state_{i}'] = state_val[i]
                            row[label.lower()] = state_val[i]  # ë ˆì´ë¸”ëª…ìœ¼ë¡œë„ ì ‘ê·¼ ê°€ëŠ¥
                        else:
                            row[f'state_{i}'] = 0.0
                            row[label.lower()] = 0.0
                    
                    # ì•¡ì…˜ ì°¨ì›ë³„ ê°œë³„ ì—´ ì¶”ê°€
                    if isinstance(action_val, list):
                        for i, val in enumerate(action_val):
                            row[f'action_{i}'] = val
                    else:
                        row['action_0'] = action_val
                    
                    # ê±´ì¶• ì„¤ê³„ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
                    row.update(self._calculate_design_quality_metrics(state_val))
                    
                    df_list.append(row)
                    
                except Exception as e:
                    print(f"í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}, í•­ëª© ê±´ë„ˆëœ€")
                    continue
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            if df_list:
                self.zmq_data = pd.DataFrame(df_list)
                
                # connection_test íƒ€ì… ì œì™¸í•˜ê³  ë°ì´í„°ë§Œ í•„í„°ë§
                self.zmq_data_filtered = self.zmq_data[self.zmq_data['type'] != 'connection_test'].copy()
                
                # ì‹œê°„ ê¸°ì¤€ ì •ë ¬
                self.zmq_data_filtered.sort_values('timestamp', inplace=True)
                
                # ì‹œê°„ ë³€í™˜
                try:
                    self.zmq_data_filtered['datetime'] = pd.to_datetime(self.zmq_data_filtered['timestamp'], unit='ms')
                except Exception as e:
                    print(f"ì‹œê°„ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}, datetime ì—´ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                
                print(f"ZMQ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.zmq_data_filtered)} ê°œ ë°ì´í„° í¬ì¸íŠ¸")
                
                # ìƒíƒœ ë° ì•¡ì…˜ ì°¨ì› ê³„ì‚°
                self._analyze_dimensions()
            else:
                print("ìœ íš¨í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.zmq_data = pd.DataFrame()
                self.zmq_data_filtered = pd.DataFrame()
            
        except Exception as e:
            print(f"ZMQ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            self.zmq_data = pd.DataFrame()
            self.zmq_data_filtered = pd.DataFrame()
    
    def _parse_json_lines(self, content):
        """ë¼ì¸ë³„ JSON íŒŒì‹±"""
        data = []
        lines = content.split('\n')
        
        start_idx = 0
        end_idx = len(lines)
        
        if lines[0].strip() == "[":
            start_idx = 1
        if lines[-1].strip() in ["]", "],", "}]"]:
            end_idx = -1
        
        for line in lines[start_idx:end_idx]:
            line = line.strip()
            if not line or line in ["[", "]", "},", "}"]:
                continue
            
            if line.endswith(","):
                line = line[:-1]
            
            if not line.endswith("}"):
                if "{" in line and "}" not in line:
                    line += "}"
            
            try:
                item = json.loads(line)
                data.append(item)
            except json.JSONDecodeError:
                print(f"ê²½ê³ : ë‹¤ìŒ ë¼ì¸ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {line[:50]}...")
        
        return data
    
    def _calculate_design_quality_metrics(self, state_values):
        """ê±´ì¶• ì„¤ê³„ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°"""
        if len(state_values) < self.state_dimensions:
            return {
                'quality_score': 0.0,
                'constraint_violations': 4,
                'legal_compliance': False,
                'sustainability_score': 0.0
            }
        
        bcr = state_values[0]  # Building Coverage Ratio
        far = state_values[1]  # Floor Area Ratio  
        sunlight = state_values[2]  # Winter Sunlight
        svr = state_values[3]  # Surface to Volume Ratio
        
        # ì œì•½ ì¡°ê±´ ìœ„ë°˜ ì²´í¬
        violations = 0
        if bcr > self.design_constraints['bcr_limit']:
            violations += 1
        if far < self.design_constraints['far_min'] or far > self.design_constraints['far_max']:
            violations += 1
        if sunlight < self.design_constraints['sunlight_min']:
            violations += 1
        if not (self.design_constraints['svr_range'][0] <= svr <= self.design_constraints['svr_range'][1]):
            violations += 1
        
        # ë²•ì  ì¤€ìˆ˜ ì—¬ë¶€
        legal_compliance = (bcr <= self.design_constraints['bcr_limit'] and 
                          self.design_constraints['far_min'] <= far <= self.design_constraints['far_max'])
        
        # ì§€ì†ê°€ëŠ¥ì„± ì ìˆ˜ (ì¼ì¡°ëŸ‰ + SVë¹„ìœ¨ ê¸°ë°˜)
        sunlight_score = min(1.0, max(0.0, (sunlight - self.design_constraints['sunlight_min']) / 
                                      (self.design_constraints['sunlight_max'] - self.design_constraints['sunlight_min'])))
        svr_score = 1.0 - abs(svr - self.design_constraints['svr_optimal']) / 0.4  # 0.4~1.2 ë²”ìœ„ì—ì„œ 0.8ì´ ìµœì 
        svr_score = max(0.0, min(1.0, svr_score))
        
        sustainability_score = (sunlight_score + svr_score) / 2.0
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        quality_score = (4 - violations) / 4.0 * 0.5 + sustainability_score * 0.5
        
        return {
            'quality_score': quality_score,
            'constraint_violations': violations,
            'legal_compliance': legal_compliance,
            'sustainability_score': sustainability_score
        }
    
    def _analyze_dimensions(self):
        """ìƒíƒœ ë° ì•¡ì…˜ ì°¨ì› ë¶„ì„"""
        if self.zmq_data_filtered.empty:
            self.state_dim = self.state_dimensions
            self.action_dim = 0
            return
        
        # ìƒíƒœ ì°¨ì› (ê³ ì •)
        self.state_dim = self.state_dimensions
        
        # ì•¡ì…˜ ì°¨ì› ì°¾ê¸°
        action_cols = [col for col in self.zmq_data_filtered.columns if col.startswith('action_')]
        self.action_dim = len(action_cols)
        
        print(f"ìƒíƒœ ì°¨ì›: {self.state_dim} ({', '.join(self.state_labels)})")
        print(f"ì•¡ì…˜ ì°¨ì›: {self.action_dim}")

    def analyze_design_diversity_for_comparison(self, n_clusters=5, samples_per_cluster=5):
        """ìŒëŒ€ë¹„êµë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ë””ìì¸ ë¶„ì„ ë° ì„ ë³„"""
        if self.zmq_data_filtered.empty:
            print("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
        
        try:
            from sklearn.cluster import KMeans
            from sklearn.preprocessing import StandardScaler
            
            # í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ íŠ¹ì§• ì„ íƒ (í™•ì¥ëœ ìƒíƒœ ê³µê°„)
            feature_cols = [f'state_{i}' for i in range(self.state_dimensions)]
            
            if not all(col in self.zmq_data_filtered.columns for col in feature_cols):
                print("í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ ìƒíƒœ ë°ì´í„°ê°€ ì™„ì „í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return None, None
            
            # ë°ì´í„° ì „ì²˜ë¦¬
            X = self.zmq_data_filtered[feature_cols].copy()
            X = X.replace([np.inf, -np.inf], np.nan).dropna()
            
            if X.empty:
                print("ì „ì²˜ë¦¬ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None, None
            
            # í’ˆì§ˆ ì ìˆ˜ê°€ ìˆëŠ” ë°ì´í„°ë§Œ ì„ íƒ (ë²•ì  ì¤€ìˆ˜ ìš°ì„ )
            valid_designs = self.zmq_data_filtered.loc[X.index].copy()
            legal_designs = valid_designs[valid_designs['legal_compliance'] == True]
            
            print(f"ì „ì²´ ë””ìì¸: {len(valid_designs)}, ë²•ì  ì¤€ìˆ˜ ë””ìì¸: {len(legal_designs)}")
            
            # ë²•ì  ì¤€ìˆ˜ ë””ìì¸ì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ í’ˆì§ˆ ì ìˆ˜ ìƒìœ„ 50% ì‚¬ìš©
            if len(legal_designs) < n_clusters * samples_per_cluster:
                print("ë²•ì  ì¤€ìˆ˜ ë””ìì¸ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í’ˆì§ˆ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì„ ë³„í•©ë‹ˆë‹¤.")
                quality_threshold = valid_designs['quality_score'].quantile(0.5)
                good_designs = valid_designs[valid_designs['quality_score'] >= quality_threshold]
                cluster_source = good_designs
            else:
                cluster_source = legal_designs
            
            # í´ëŸ¬ìŠ¤í„°ë§ ëŒ€ìƒ ë°ì´í„° ì¤€ë¹„
            cluster_features = cluster_source[feature_cols]
            
            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(cluster_features)
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§
            n_clusters = min(n_clusters, len(cluster_source) // 2)  # í´ëŸ¬ìŠ¤í„° ìˆ˜ ì¡°ì •
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(X_scaled)
            
            # í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¶”ê°€
            cluster_source = cluster_source.copy()
            cluster_source['cluster'] = clusters
            
            # ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ë‹¤ì–‘í•œ ìƒ˜í”Œ ì„ íƒ
            diverse_designs = []
            cluster_stats = []
            
            for i in range(n_clusters):
                cluster_data = cluster_source[cluster_source['cluster'] == i]
                if cluster_data.empty:
                    continue
                
                # í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ë³´ìƒ ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
                cluster_sorted = cluster_data.sort_values('reward', ascending=False)
                
                # ìƒìœ„, ì¤‘ìœ„, í•˜ìœ„ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
                n_samples = min(samples_per_cluster, len(cluster_sorted))
                if n_samples >= 3:
                    # ìƒìœ„ 1/3, ì¤‘ìœ„ 1/3, í•˜ìœ„ 1/3ì—ì„œ ì„ íƒ
                    indices = [
                        0,  # ìµœê³ 
                        len(cluster_sorted) // 3,  # ì¤‘ìƒìœ„
                        len(cluster_sorted) * 2 // 3,  # ì¤‘í•˜ìœ„
                    ]
                    if n_samples > 3:
                        # ì¶”ê°€ ìƒ˜í”Œë“¤ì„ ê· ë“±í•˜ê²Œ ë¶„ë°°
                        additional = np.linspace(0, len(cluster_sorted)-1, n_samples, dtype=int)
                        indices = sorted(set(list(additional)))
                else:
                    indices = list(range(n_samples))
                
                selected_designs = cluster_sorted.iloc[indices[:n_samples]]
                
                for _, design in selected_designs.iterrows():
                    diverse_designs.append(design)
                
                # í´ëŸ¬ìŠ¤í„° í†µê³„
                cluster_stats.append({
                    'cluster': i,
                    'size': len(cluster_data),
                    'avg_reward': cluster_data['reward'].mean(),
                    'avg_quality': cluster_data['quality_score'].mean(),
                    'legal_compliance_rate': cluster_data['legal_compliance'].mean(),
                    'selected_count': len(selected_designs)
                })
            
            diverse_designs_df = pd.DataFrame(diverse_designs)
            cluster_stats_df = pd.DataFrame(cluster_stats)
            
            print(f"\n=== ìŒëŒ€ë¹„êµìš© ë‹¤ì–‘í•œ ë””ìì¸ ì„ ë³„ ê²°ê³¼ ===")
            print(f"ì´ ì„ ë³„ëœ ë””ìì¸: {len(diverse_designs_df)}ê°œ")
            print("í´ëŸ¬ìŠ¤í„°ë³„ í†µê³„:")
            print(cluster_stats_df.to_string(index=False))
            
            return diverse_designs_df, cluster_stats_df
            
        except ImportError:
            print("í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•´ scikit-learn ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return None, None
        except Exception as e:
            print(f"ë‹¤ì–‘ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return None, None

    def find_optimal_designs_for_comparison(self, top_n=10, quality_weight=0.3, reward_weight=0.7):
        """ìŒëŒ€ë¹„êµë¥¼ ìœ„í•œ ìµœì  ë””ìì¸ ì°¾ê¸° (ë³µí•© ì ìˆ˜ ê¸°ì¤€)"""
        if self.zmq_data_filtered.empty:
            print("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ë³µí•© ì ìˆ˜ ê³„ì‚° (ë³´ìƒ + í’ˆì§ˆ)
        reward_normalized = (self.zmq_data_filtered['reward'] - self.zmq_data_filtered['reward'].min()) / \
                           (self.zmq_data_filtered['reward'].max() - self.zmq_data_filtered['reward'].min())
        
        quality_normalized = self.zmq_data_filtered['quality_score']
        
        composite_score = reward_weight * reward_normalized + quality_weight * quality_normalized
        self.zmq_data_filtered = self.zmq_data_filtered.copy()
        self.zmq_data_filtered['composite_score'] = composite_score
        
        # ë³µí•© ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ Nê°œ ì„ íƒ
        top_designs = self.zmq_data_filtered.sort_values('composite_score', ascending=False).head(top_n).copy()
        
        # ê²°ê³¼ ì¶œë ¥ìš© ì¹¼ëŸ¼ ì„ íƒ
        result_cols = ['design_id', 'msg_id', 'reward', 'quality_score', 'composite_score', 
                      'legal_compliance', 'sustainability_score', 'datetime']
        
        # ìƒíƒœ ê°’ë“¤ ì¶”ê°€
        for i, label in enumerate(self.state_labels):
            result_cols.append(f'state_{i}')
            result_cols.append(label.lower())
        
        # ì•¡ì…˜ ê°’ë“¤ ì¶”ê°€
        action_cols = [col for col in self.zmq_data_filtered.columns if col.startswith('action_')]
        result_cols.extend(action_cols)
        
        # ì¡´ì¬í•˜ëŠ” ì¹¼ëŸ¼ë§Œ ì„ íƒ
        available_cols = [col for col in result_cols if col in top_designs.columns]
        result_df = top_designs[available_cols].reset_index(drop=True)
        
        print(f"\n=== ìŒëŒ€ë¹„êµìš© ìµœì  ë””ìì¸ (ìƒìœ„ {len(result_df)}ê°œ) ===")
        print(f"ë³µí•© ì ìˆ˜ êµ¬ì„±: ë³´ìƒ({reward_weight:.1f}) + í’ˆì§ˆ({quality_weight:.1f})")
        
        for idx, row in result_df.iterrows():
            print(f"\në””ìì¸ {idx+1}: ID={row.get('design_id', 'N/A')}")
            print(f"  ë³µí•©ì ìˆ˜: {row.get('composite_score', 0):.4f} (ë³´ìƒ: {row.get('reward', 0):.4f}, í’ˆì§ˆ: {row.get('quality_score', 0):.4f})")
            print(f"  ë²•ì ì¤€ìˆ˜: {'ì˜ˆ' if row.get('legal_compliance', False) else 'ì•„ë‹ˆì˜¤'}")
            print(f"  BCR: {row.get('bcr', 0)*100:.1f}%, FAR: {row.get('far', 0)*100:.1f}%")
            print(f"  ì¼ì¡°ëŸ‰: {row.get('winter_sunlight', 0)/1000:.1f}k kWh, SVë¹„ìœ¨: {row.get('sv_ratio', 0):.3f}")
        
        return result_df

    def generate_rlhf_comparison_dataset(self, output_path, top_n=15, diverse_n=20):
        """RLHF ìŒëŒ€ë¹„êµë¥¼ ìœ„í•œ ê¸°ì¤€ ë°ì´í„°ì…‹ ìƒì„±"""
        if self.zmq_data_filtered.empty:
            print("ê¸°ì¤€ ë°ì´í„° ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            # 1. ìµœì  ë””ìì¸ ì„ ë³„
            print("1. ìµœì  ë””ìì¸ ì„ ë³„ ì¤‘...")
            top_designs = self.find_optimal_designs_for_comparison(top_n=top_n)
            
            # 2. ë‹¤ì–‘í•œ ë””ìì¸ ì„ ë³„  
            print("2. ë‹¤ì–‘í•œ ë””ìì¸ ì„ ë³„ ì¤‘...")
            diverse_designs, cluster_stats = self.analyze_design_diversity_for_comparison(
                n_clusters=5, samples_per_cluster=diverse_n//5
            )
            
            if diverse_designs is None:
                diverse_designs = pd.DataFrame()
            
            # 3. ê¸°ì¤€ ë°ì´í„°ì…‹ êµ¬ì„±
            reference_dataset = {
                'format_version': "2.0",
                'system_type': "RLHF_pairwise_comparison", 
                'metadata': {
                    'generated_at': datetime.now().isoformat(),
                    'total_samples': len(self.zmq_data_filtered),
                    'state_dimensions': self.state_dimensions,
                    'state_labels': self.state_labels,
                    'design_constraints': self.design_constraints,
                    'selection_criteria': {
                        'top_designs_count': len(top_designs),
                        'diverse_designs_count': len(diverse_designs),
                        'composite_score_weights': {'reward': 0.7, 'quality': 0.3}
                    }
                },
                'top_designs': [],
                'diverse_designs': [],
                'cluster_statistics': cluster_stats.to_dict('records') if cluster_stats is not None else []
            }
            
            # 4. ìµœê³  ì„±ëŠ¥ ë””ìì¸ ë°ì´í„° ì¶”ê°€
            for idx, row in top_designs.iterrows():
                design_data = {
                    'id': row.get('design_id', f"top_{idx}_{int(time.time())}"),
                    'msg_id': int(row.get('msg_id', 0)),
                    'timestamp': int(row.get('timestamp', time.time() * 1000)),
                    'reward': float(row.get('reward', 0.0)),
                    'quality_score': float(row.get('quality_score', 0.0)),
                    'composite_score': float(row.get('composite_score', 0.0)),
                    'legal_compliance': bool(row.get('legal_compliance', False)),
                    'sustainability_score': float(row.get('sustainability_score', 0.0)),
                    'constraint_violations': int(row.get('constraint_violations', 0)),
                    'state': [float(row.get(f'state_{i}', 0.0)) for i in range(self.state_dimensions)],
                    'state_labels': dict(zip(self.state_labels, 
                                           [float(row.get(f'state_{i}', 0.0)) for i in range(self.state_dimensions)])),
                    'action': [float(row.get(f'action_{i}', 0.0)) for i in range(self.action_dim) 
                              if f'action_{i}' in row],
                    'type': 'top_performance'
                }
                reference_dataset['top_designs'].append(design_data)
            
            # 5. ë‹¤ì–‘í•œ ë””ìì¸ ë°ì´í„° ì¶”ê°€
            if not diverse_designs.empty:
                for idx, row in diverse_designs.iterrows():
                    design_data = {
                        'id': row.get('design_id', f"diverse_{idx}_{int(time.time())}"),
                        'msg_id': int(row.get('msg_id', 0)),
                        'timestamp': int(row.get('timestamp', time.time() * 1000)),
                        'reward': float(row.get('reward', 0.0)),
                        'quality_score': float(row.get('quality_score', 0.0)),
                        'composite_score': float(row.get('composite_score', 0.0)) if 'composite_score' in row else 0.0,
                        'legal_compliance': bool(row.get('legal_compliance', False)),
                        'sustainability_score': float(row.get('sustainability_score', 0.0)),
                        'constraint_violations': int(row.get('constraint_violations', 0)),
                        'cluster': int(row.get('cluster', -1)),
                        'state': [float(row.get(f'state_{i}', 0.0)) for i in range(self.state_dimensions)],
                        'state_labels': dict(zip(self.state_labels, 
                                               [float(row.get(f'state_{i}', 0.0)) for i in range(self.state_dimensions)])),
                        'action': [float(row.get(f'action_{i}', 0.0)) for i in range(self.action_dim) 
                                  if f'action_{i}' in row],
                        'type': 'diverse_exploration'
                    }
                    reference_dataset['diverse_designs'].append(design_data)
            
            # 6. ì €ì¥ í´ë” í™•ì¸
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # 7. JSON íŒŒì¼ë¡œ ì €ì¥
            with open(output_path, 'w') as f:
                json.dump(reference_dataset, f, indent=2, ensure_ascii=False)
            
            print(f"\nâœ… RLHF ìŒëŒ€ë¹„êµ ê¸°ì¤€ ë°ì´í„°ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ“Š ìµœê³  ì„±ëŠ¥ ë””ìì¸: {len(reference_dataset['top_designs'])}ê°œ")
            print(f"ğŸ¯ ë‹¤ì–‘í•œ íƒìƒ‰ ë””ìì¸: {len(reference_dataset['diverse_designs'])}ê°œ")
            print(f"ğŸ“ˆ ì´ ë¹„êµ ê°€ëŠ¥í•œ ë””ìì¸: {len(reference_dataset['top_designs']) + len(reference_dataset['diverse_designs'])}ê°œ")
            
            return reference_dataset
            
        except Exception as e:
            print(f"RLHF ê¸°ì¤€ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return None

    # ë‚˜ë¨¸ì§€ ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ìœ ì§€...
    def _load_ppo_log(self):
        """PPO í•™ìŠµ ë¡œê·¸ íŒŒì¼ ë¡œë“œ (CSV í˜•ì‹)"""
        try:
            self.ppo_log_data = pd.read_csv(self.ppo_log_path)
            print(f"PPO ë¡œê·¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.ppo_log_data)} ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        except Exception as e:
            print(f"PPO ë¡œê·¸ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.ppo_log_data = pd.DataFrame()
    
    def _load_model_info(self):
        """PPO ëª¨ë¸ ì •ë³´ ë¡œë“œ"""
        try:
            model_info = {}
            
            # ë²„ì „ ì •ë³´ í™•ì¸
            version_file = os.path.join(self.model_dir, "_stable_baselines3_version")
            if os.path.exists(version_file):
                with open(version_file, 'r') as f:
                    model_info['sb3_version'] = f.read().strip()
            
            self.model_info = model_info
            print(f"ëª¨ë¸ ì •ë³´ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"ëª¨ë¸ ì •ë³´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.model_info = {}

    def save_processed_data(self, output_path):
        """ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        if self.zmq_data_filtered.empty:
            print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            # í•„ìš”í•œ ì—´ë§Œ ì„ íƒ
            cols_to_save = ['design_id', 'msg_id', 'timestamp', 'datetime', 'reward', 
                           'quality_score', 'legal_compliance', 'sustainability_score']
            
            # ìƒíƒœ ê°’ë“¤ ì¶”ê°€
            for i in range(self.state_dimensions):
                cols_to_save.append(f'state_{i}')
            for label in self.state_labels:
                cols_to_save.append(label.lower())
            
            # ì•¡ì…˜ ê°’ë“¤ ì¶”ê°€
            action_cols = [col for col in self.zmq_data_filtered.columns if col.startswith('action_')]
            cols_to_save.extend(action_cols)
            
            # ì¡´ì¬í•˜ëŠ” ì—´ë§Œ ì„ íƒ
            existing_cols = [col for col in cols_to_save if col in self.zmq_data_filtered.columns]
            
            # ì €ì¥ í´ë” í™•ì¸
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # ë°ì´í„° ì €ì¥
            self.zmq_data_filtered[existing_cols].to_csv(output_path, index=False)
            print(f"ì²˜ë¦¬ëœ ë°ì´í„°ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def find_latest_file(directory, pattern, subdirectory=None):
    """ì§€ì •ëœ í´ë”ì—ì„œ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ì¥ ìµœì‹  íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    import glob
    
    search_dir = os.path.join(directory, subdirectory) if subdirectory else directory
    files = glob.glob(os.path.join(search_dir, pattern))
    
    if not files:
        return None
    
    # ìµœì‹  íŒŒì¼ ì°¾ê¸° (ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def create_session_directory(base_dir, session_name=None):
    """ì„¸ì…˜ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    
    if session_name:
        dir_name = f"{session_name}_{timestamp}"
    else:
        dir_name = f"rlhf_session_{timestamp}"
    
    session_dir = os.path.join(base_dir, dir_name)
    os.makedirs(session_dir, exist_ok=True)
    
    return session_dir

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='RLHF ìŒëŒ€ë¹„êµìš© ë°ì´í„° ë¶„ì„ ë° ì¤€ë¹„ ë„êµ¬')
    parser.add_argument('--state-reward-log', type=str, default=None,
                        help='ZMQë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ìƒíƒœ/ë³´ìƒ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--model-dir', type=str, default='.',
                        help='PPO ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--output-dir', type=str, default='data',
                        help='ê²°ê³¼ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--session-name', type=str, default=None,
                        help='ì„¸ì…˜ ì´ë¦„')
    parser.add_argument('--top-designs', type=int, default=15,
                        help='ì„ ë³„í•  ìµœê³  ì„±ëŠ¥ ë””ìì¸ ìˆ˜')
    parser.add_argument('--diverse-designs', type=int, default=20, 
                        help='ì„ ë³„í•  ë‹¤ì–‘í•œ ë””ìì¸ ìˆ˜')
    
    args = parser.parse_args()
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ê³„ì‚°
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if not os.path.isabs(args.output_dir):
        args.output_dir = os.path.join(project_root, args.output_dir)
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ì„¸ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±
    session_dir = create_session_directory(args.output_dir, args.session_name)
    print(f"\nğŸ”¹ RLHF ë¶„ì„ ì„¸ì…˜ ë””ë ‰í† ë¦¬: {session_dir}")
    
    # ìƒíƒœ/ë³´ìƒ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ê²°ì •
    state_reward_log_path = args.state_reward_log
    if not state_reward_log_path:
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  íŒŒì¼ ì°¾ê¸°
        zmq_logs_dir = os.path.join(project_root, "data", "zmq_logs")
        state_reward_log_path = find_latest_file(zmq_logs_dir, "state_reward_log_*.json")
        
        if not state_reward_log_path:
            # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
            state_reward_log_path = find_latest_file(".", "state_reward_log_*.json")
            
        if not state_reward_log_path:
            print("âŒ ìƒíƒœ/ë³´ìƒ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. --state-reward-logë¡œ ì§ì ‘ ì§€ì •í•´ì£¼ì„¸ìš”.")
            return
    
    print(f"ğŸ“‚ ì‚¬ìš©í•  ìƒíƒœ/ë³´ìƒ ë¡œê·¸ íŒŒì¼: {state_reward_log_path}")
    
    # ë¶„ì„ê¸° ìƒì„±
    analyzer = RLHFDataAnalyzer(
        state_reward_log_path=state_reward_log_path,
        model_dir=args.model_dir,
        session_dir=session_dir
    )
    
    # ë°ì´í„° í™•ì¸
    if analyzer.zmq_data_filtered.empty:
        print("\nâŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“Š ë¡œë“œëœ ë°ì´í„°: {len(analyzer.zmq_data_filtered)}ê°œ ë””ìì¸")
    print(f"ğŸ“ ìƒíƒœ ì°¨ì›: {analyzer.state_dimensions} ({', '.join(analyzer.state_labels)})")
    print(f"ğŸ¯ ì•¡ì…˜ ì°¨ì›: {analyzer.action_dim}")
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    processed_data_file = os.path.join(session_dir, "processed_rlhf_data.csv")
    reference_data_file = os.path.join(session_dir, "rlhf_reference_data.json")
    
    # 1. ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
    print("\n1ï¸âƒ£ ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì¤‘...")
    analyzer.save_processed_data(processed_data_file)
    
    # 2. RLHF ìŒëŒ€ë¹„êµìš© ê¸°ì¤€ ë°ì´í„° ìƒì„±
    print("\n2ï¸âƒ£ RLHF ìŒëŒ€ë¹„êµìš© ê¸°ì¤€ ë°ì´í„° ìƒì„± ì¤‘...")
    reference_data = analyzer.generate_rlhf_comparison_dataset(
        reference_data_file, 
        top_n=args.top_designs, 
        diverse_n=args.diverse_designs
    )
    
    if reference_data:
        print(f"\nâœ… RLHF ìŒëŒ€ë¹„êµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
        print(f"ğŸ“ ì„¸ì…˜ ë””ë ‰í† ë¦¬: {session_dir}")
        print(f"ğŸ“„ ê¸°ì¤€ ë°ì´í„°: {reference_data_file}")
        print(f"ğŸ“ˆ ì²˜ë¦¬ëœ ë°ì´í„°: {processed_data_file}")
        print(f"\nğŸ”„ ë‹¤ìŒ ë‹¨ê³„: design_regenerator.py ì‹¤í–‰í•˜ì—¬ 3D ë©”ì‹œ ìƒì„±")
    else:
        print(f"\nâŒ ê¸°ì¤€ ë°ì´í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()