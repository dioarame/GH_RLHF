#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ì•¡ì…˜ ë³€í™” ì¶”ì´ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (ê°œì„ ëœ ë²„ì „)
- RL ì—ì´ì „íŠ¸ì˜ ì•¡ì…˜ ê°’ ë³€í™” íŒ¨í„´ ë¶„ì„
- ë³´ìƒ í•¨ìˆ˜ë³„ íƒìƒ‰ í–‰ë™ ë¹„êµ
- ì•¡ì…˜ ê³µê°„ íƒìƒ‰ ì „ëµ ì‹œê°í™”
- ì´ˆê¸°í™” ì•¡ì…˜ ê°’ í•„í„°ë§ ë° í•™ìŠµ ë‹¨ê³„ë³„ ì •êµí•œ ë¶„ì„
"""

import os
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings

# ê²½ê³  ì–µì œ
warnings.filterwarnings('ignore')
os.environ['LOKY_MAX_CPU_COUNT'] = '4'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ê°œì„ ëœ ë²„ì „)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_action_data(data_path, strategy_type):
    """ì•¡ì…˜ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ì´ˆê¸°í™” ê°’ ê°ì§€ ë° í•„í„°ë§ í¬í•¨)"""
    
    print(f"Loading action data: {data_path}")
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not data_path.exists():
        raise FileNotFoundError(f"Data file not found: {data_path}")
    
    try:
        # CSV ë¡œë“œ (í—¤ë” ìë™ ì²˜ë¦¬)
        first_line = open(data_path, 'r').readline().strip()
        if 'timestamp' in first_line.lower():
            df = pd.read_csv(data_path)
        else:
            # í—¤ë” ì—†ëŠ” ê²½ìš°
            df = pd.read_csv(data_path, header=None)
            
            if len(df.columns) >= 9:
                base_cols = ['timestamp', 'step', 'is_closed_brep', 'excluded_from_training', 
                            'bcr', 'far', 'winter_sunlight', 'sv_ratio', 'reward']
                action_cols = [f'action{i+1}' for i in range(len(df.columns) - len(base_cols))]
                df.columns = base_cols + action_cols
            else:
                raise ValueError(f"Unexpected column count: {len(df.columns)}")
    
    except Exception as e:
        raise Exception(f"Error loading CSV: {e}")
    
    print(f"Original data: {len(df):,} rows")
    
    # ì•¡ì…˜ ì»¬ëŸ¼ ì‹ë³„
    action_cols = [col for col in df.columns if col.startswith('action')]
    if not action_cols:
        raise ValueError("No action columns found!")
    
    print(f"Action columns detected: {action_cols}")
    
    # ë°ì´í„° íƒ€ì… ë³€í™˜
    numeric_cols = ['bcr', 'far', 'winter_sunlight', 'sv_ratio', 'reward'] + action_cols
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # ê¸°ë³¸ í•„í„°ë§
    original_count = len(df)
    df = df[df['is_closed_brep'] == 1]  # ìœ íš¨í•œ í˜•íƒœë§Œ
    df = df[df['excluded_from_training'] == 0]  # í•™ìŠµ í¬í•¨ ë°ì´í„°ë§Œ
    df = df.dropna(subset=numeric_cols)  # ê²°ì¸¡ì¹˜ ì œê±°
    
    print(f"After basic filtering: {len(df):,} rows (removed: {original_count - len(df):,})")
    
    # ì´ˆê¸°í™” ì•¡ì…˜ ê°ì§€ ë° ì œê±°
    df = detect_and_filter_initialization_actions(df, action_cols)
    
    if len(df) == 0:
        raise ValueError("No valid data after filtering!")
    
    # ì•¡ì…˜ ì •ê·œí™” (ì‹¤ì œ ìŠ¬ë¼ì´ë” ê°’ì„ -1~1 ë²”ìœ„ë¡œ ì—­ë³€í™˜)
    # ì‹¤ì œ ìŠ¬ë¼ì´ë” ë²”ìœ„ ìë™ ê°ì§€ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
    slider_ranges = auto_detect_slider_ranges(df, action_cols)
    
    for col in action_cols:
        if col in slider_ranges:
            min_val, max_val = slider_ranges[col]
            # ì‹¤ì œ ê°’ì„ ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ì—­ë³€í™˜
            df[f'{col}_normalized'] = 2.0 * (df[col] - min_val) / (max_val - min_val) - 1.0
            df[f'{col}_normalized'] = df[f'{col}_normalized'].clip(-1.0, 1.0)
        else:
            # ë²”ìœ„ë¥¼ ëª¨ë¥´ëŠ” ê²½ìš° ë°ì´í„° ê¸°ë°˜ ì •ê·œí™”
            min_val, max_val = df[col].min(), df[col].max()
            if max_val > min_val:
                df[f'{col}_normalized'] = 2.0 * (df[col] - min_val) / (max_val - min_val) - 1.0
            else:
                df[f'{col}_normalized'] = 0.0
    
    # í•™ìŠµ ë‹¨ê³„ êµ¬ë¶„ (ë” ì •êµí•œ êµ¬ë¶„)
    df = add_learning_phases(df)
    
    # ì•¡ì…˜ ë³€í™”ëŸ‰ ê³„ì‚° (íƒìƒ‰ í™œë™ë„ ì¸¡ì •ìš©)
    df = add_action_dynamics(df, action_cols)
    
    return df, action_cols

def detect_and_filter_initialization_actions(df, action_cols):
    """ì´ˆê¸°í™” ì•¡ì…˜ ê°ì§€ ë° í•„í„°ë§"""
    
    original_count = len(df)
    
    # 1. ì´ˆê¸° ìŠ¤í…ë“¤ ì¤‘ ë™ì¼í•œ ì•¡ì…˜ ê°’ì„ ê°€ì§„ ê²ƒë“¤ ê°ì§€
    # ë³´í†µ ì²˜ìŒ ëª‡ ìŠ¤í…ì€ ì´ˆê¸°í™” ì•¡ì…˜ì´ ë°˜ë³µë¨
    initial_steps = min(10, len(df) // 10)  # ì²˜ìŒ 10ê°œ ë˜ëŠ” ì „ì²´ì˜ 10%
    
    if len(df) > initial_steps:
        initial_data = df.head(initial_steps)
        
        # ëª¨ë“  ì•¡ì…˜ì´ ë™ì¼í•œ ê°’ì„ ê°€ì§€ëŠ” í–‰ë“¤ ì°¾ê¸°
        identical_action_mask = pd.Series([False] * len(df))
        
        for _, row in initial_data.iterrows():
            # í˜„ì¬ í–‰ê³¼ ë™ì¼í•œ ì•¡ì…˜ ì¡°í•©ì„ ê°€ì§„ ëª¨ë“  í–‰ ì°¾ê¸°
            mask = pd.Series([True] * len(df))
            for col in action_cols:
                mask &= (abs(df[col] - row[col]) < 0.001)  # ê±°ì˜ ë™ì¼í•œ ê°’
            
            # ë™ì¼í•œ ì•¡ì…˜ ì¡°í•©ì´ 5ê°œ ì´ìƒì´ë©´ ì´ˆê¸°í™”ë¡œ ê°„ì£¼
            if mask.sum() >= 5:
                identical_action_mask |= mask
        
        # 2. ì¶”ê°€ í•„í„°ë§: ëª¨ë“  ì•¡ì…˜ì´ íŠ¹ì • ê°’ìœ¼ë¡œ ë™ì¼í•œ ê²½ìš° (ì˜ˆ: ëª¨ë‘ 0 ë˜ëŠ” ì¤‘ê°„ê°’)
        for col in action_cols:
            # íŠ¹ì • ê°’ì— ì§‘ì¤‘ëœ ë°ì´í„° ê°ì§€ (ì „ì²´ì˜ 20% ì´ìƒì´ ë™ì¼í•œ ê°’)
            value_counts = df[col].round(2).value_counts()
            if len(value_counts) > 0:
                most_common_value = value_counts.index[0]
                most_common_count = value_counts.iloc[0]
                
                if most_common_count > len(df) * 0.2:  # 20% ì´ìƒì´ ê°™ì€ ê°’
                    print(f"âš ï¸ {col}ì—ì„œ {most_common_value} ê°’ì´ {most_common_count}íšŒ ({most_common_count/len(df)*100:.1f}%) ë°˜ë³µë¨")
                    
                    # í•´ë‹¹ ê°’ë“¤ì„ ì´ˆê¸°í™”ë¡œ ê°„ì£¼í•˜ë˜, ë„ˆë¬´ ë§ì´ ì œê±°í•˜ì§€ ì•Šë„ë¡ ì¡°ì‹¬
                    if most_common_count < len(df) * 0.5:  # 50% ë¯¸ë§Œì¼ ë•Œë§Œ ì œê±°
                        identical_action_mask |= (abs(df[col] - most_common_value) < 0.001)
        
        # 3. ì—°ì†ëœ ë™ì¼ ì•¡ì…˜ ì‹œí€€ìŠ¤ ê°ì§€
        for col in action_cols:
            # ì—°ì†ëœ 5ê°œ ì´ìƒì˜ ë™ì¼í•œ ê°’ ì°¾ê¸°
            diff = df[col].diff().fillna(1)  # ì²« ë²ˆì§¸ëŠ” ë³€í™”ë¡œ ê°„ì£¼
            same_value_groups = (diff != 0).cumsum()
            group_sizes = same_value_groups.value_counts()
            
            # 5ê°œ ì´ìƒ ì—°ì†ëœ ê·¸ë£¹ë“¤ ì°¾ê¸°
            large_groups = group_sizes[group_sizes >= 5].index
            for group_id in large_groups:
                group_mask = (same_value_groups == group_id)
                if group_mask.sum() >= 5:
                    print(f"âš ï¸ {col}ì—ì„œ {group_mask.sum()}ê°œì˜ ì—°ì†ëœ ë™ì¼ ê°’ ê°ì§€")
                    identical_action_mask |= group_mask
        
        # í•„í„°ë§ ì‹¤í–‰
        if identical_action_mask.sum() > 0:
            print(f"ğŸ” ì´ˆê¸°í™” ì•¡ì…˜ìœ¼ë¡œ ê°ì§€ëœ ë°ì´í„°: {identical_action_mask.sum()}ê°œ")
            
            # ë„ˆë¬´ ë§ì´ ì œê±°í•˜ì§€ ì•Šë„ë¡ ì•ˆì „ì¥ì¹˜
            removal_ratio = identical_action_mask.sum() / len(df)
            if removal_ratio > 0.7:  # 70% ì´ìƒ ì œê±°í•˜ë ¤ í•˜ë©´ ê²½ê³ 
                print(f"âš ï¸ ë„ˆë¬´ ë§ì€ ë°ì´í„°({removal_ratio*100:.1f}%)ë¥¼ ì œê±°í•˜ë ¤ í•©ë‹ˆë‹¤. ì¼ë¶€ë§Œ ì œê±°í•©ë‹ˆë‹¤.")
                # ì´ˆê¸° 30%ë§Œ ì œê±°
                initial_portion = int(len(df) * 0.3)
                identical_action_mask = identical_action_mask & (df.index < df.index[initial_portion])
            
            df = df[~identical_action_mask]
            print(f"âœ… ì´ˆê¸°í™” ì•¡ì…˜ ì œê±° ì™„ë£Œ: {identical_action_mask.sum()}ê°œ ì œê±°, {len(df)}ê°œ ë‚¨ìŒ")
    
    removed_count = original_count - len(df)
    print(f"Total removed by initialization filter: {removed_count} rows")
    
    return df

def auto_detect_slider_ranges(df, action_cols):
    """ìŠ¬ë¼ì´ë” ë²”ìœ„ ìë™ ê°ì§€"""
    
    slider_ranges = {}
    
    # ì¼ë°˜ì ì¸ ìŠ¬ë¼ì´ë” ë²”ìœ„ íŒ¨í„´ ê°ì§€
    for col in action_cols:
        values = df[col].dropna()
        min_val, max_val = values.min(), values.max()
        value_range = max_val - min_val
        
        # ì¼ë°˜ì ì¸ íŒ¨í„´ë“¤ í™•ì¸
        if min_val >= 9 and max_val <= 26 and value_range > 10:
            # Height ê´€ë ¨ ìŠ¬ë¼ì´ë” (10~25 ë“±)
            slider_ranges[col] = (10.0, 25.0)
        elif min_val >= 45 and max_val <= 105 and value_range > 30:
            # Percentage ê´€ë ¨ ìŠ¬ë¼ì´ë” (50~100 ë“±)
            slider_ranges[col] = (50.0, 100.0)
        elif min_val >= -5 and max_val <= 105 and value_range > 50:
            # 0~100 ë²”ìœ„ ìŠ¬ë¼ì´ë”
            slider_ranges[col] = (0.0, 100.0)
        else:
            # ë°ì´í„° ê¸°ë°˜ ë²”ìœ„ ì„¤ì • (ì•½ê°„ì˜ ë§ˆì§„ ì¶”ê°€)
            margin = value_range * 0.1
            slider_ranges[col] = (min_val - margin, max_val + margin)
        
        print(f"ğŸ“ {col} ê°ì§€ëœ ë²”ìœ„: {slider_ranges[col]}")
    
    return slider_ranges

def add_learning_phases(df):
    """í•™ìŠµ ë‹¨ê³„ êµ¬ë¶„ ì¶”ê°€ (ë” ì •êµí•œ êµ¬ë¶„)"""
    
    total_steps = df['step'].max() - df['step'].min()
    
    if total_steps >= 2000:
        # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ 5ë‹¨ê³„ êµ¬ë¶„
        bins = [
            df['step'].min(),
            df['step'].min() + total_steps * 0.2,   # Early (0-20%)
            df['step'].min() + total_steps * 0.4,   # Early-Mid (20-40%)
            df['step'].min() + total_steps * 0.6,   # Mid (40-60%)
            df['step'].min() + total_steps * 0.8,   # Mid-Late (60-80%)
            df['step'].max()                        # Late (80-100%)
        ]
        labels = ['Early', 'Early-Mid', 'Middle', 'Mid-Late', 'Late']
    elif total_steps >= 500:
        # ì¤‘ê°„ ì •ë„ ë°ì´í„°ë©´ 3ë‹¨ê³„ êµ¬ë¶„
        bins = [
            df['step'].min(),
            df['step'].min() + total_steps * 0.33,
            df['step'].min() + total_steps * 0.67,
            df['step'].max()
        ]
        labels = ['Early', 'Middle', 'Late']
    else:
        # ì ì€ ë°ì´í„°ë©´ ë‹¨ì¼ ë‹¨ê³„
        df['learning_phase'] = 'All'
        df['learning_phase_numeric'] = 0.5
        return df
    
    df['learning_phase'] = pd.cut(df['step'], bins=bins, labels=labels, include_lowest=True)
    
    # ìˆ˜ì¹˜í˜• ë‹¨ê³„ ì¶”ê°€ (0~1 ì‚¬ì´)
    phase_mapping = {label: i/(len(labels)-1) for i, label in enumerate(labels)}
    df['learning_phase_numeric'] = df['learning_phase'].map(phase_mapping)
    
    return df

def add_action_dynamics(df, action_cols):
    """ì•¡ì…˜ ë³€í™”ëŸ‰ ë° íƒìƒ‰ í™œë™ë„ ê³„ì‚°"""
    
    # ì´ì „ ìŠ¤í… ëŒ€ë¹„ ì•¡ì…˜ ë³€í™”ëŸ‰ ê³„ì‚°
    for col in action_cols:
        df[f'{col}_delta'] = df[col].diff()
        df[f'{col}_abs_delta'] = df[f'{col}_delta'].abs()
    
    # ì „ì²´ ì•¡ì…˜ ë³€í™”ëŸ‰ (ëª¨ë“  ì•¡ì…˜ì˜ ë³€í™”ëŸ‰ í•©)
    delta_cols = [f'{col}_abs_delta' for col in action_cols]
    df['total_action_change'] = df[delta_cols].sum(axis=1)
    
    # íƒìƒ‰ í™œë™ë„ (ì´ë™ í‰ê· )
    window_size = min(50, len(df) // 10)
    df['exploration_activity'] = df['total_action_change'].rolling(
        window=window_size, min_periods=1
    ).mean()
    
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ê°œì„ ëœ ì•¡ì…˜ ì¶”ì´ ë¶„ì„ í•¨ìˆ˜ë“¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def create_action_trends_plot(df, action_cols, strategy_type, output_dir):
    """ì•¡ì…˜ ê°’ ë³€í™” ì¶”ì´ ê·¸ë˜í”„ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
    
    # ìŠ¤ë¬´ë”© ìœˆë„ìš° ì„¤ì •
    smooth_window = min(100, len(df) // 20)
    
    # ì„œë¸Œí”Œë¡¯ ìƒì„±
    fig, axes = plt.subplots(len(action_cols) + 1, 1, 
                            figsize=(16, 3 * (len(action_cols) + 1)), sharex=True)
    if len(action_cols) == 0:
        axes = [axes]
    
    strategy_name = "MaxMin Strategy" if strategy_type == "maxmin" else "Optimized Strategy"
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFA07A', '#98D8C8']
    
    # ê° ì•¡ì…˜ë³„ ì¶”ì´
    for i, action_col in enumerate(action_cols):
        ax = axes[i]
        
        # ì›ë³¸ ë° ìŠ¤ë¬´ë”©ëœ ë°ì´í„°
        raw_data = df[action_col]
        smoothed_data = df[action_col].rolling(window=smooth_window, min_periods=1).mean()
        
        # ì •ê·œí™”ëœ ë°ì´í„°ë„ í‘œì‹œ
        norm_col = f'{action_col}_normalized'
        if norm_col in df.columns:
            norm_smoothed = df[norm_col].rolling(window=smooth_window, min_periods=1).mean()
            
            # ë³´ì¡° ì¶• ìƒì„±
            ax2 = ax.twinx()
            ax2.plot(df['step'], norm_smoothed, color='gray', linewidth=1.5, alpha=0.8, 
                    linestyle='--', label='Normalized (-1~1)')
            ax2.set_ylabel('Normalized Value', color='gray', fontsize=10)
            ax2.set_ylim(-1.2, 1.2)
            ax2.tick_params(axis='y', labelcolor='gray')
            ax2.axhline(0, color='gray', linestyle=':', alpha=0.5)
        
        # ë©”ì¸ ë°ì´í„° í”Œë¡¯
        ax.plot(df['step'], raw_data, alpha=0.3, color='lightgray', linewidth=0.5, label='Raw')
        ax.plot(df['step'], smoothed_data, color=colors[i % len(colors)], linewidth=2.5, 
               label=f'Smoothed (window={smooth_window})')
        
        # í•™ìŠµ ë‹¨ê³„ë³„ ë°°ê²½ìƒ‰
        if 'learning_phase' in df.columns and len(df['learning_phase'].unique()) > 1:
            add_phase_backgrounds(ax, df)
        
        # ì•¡ì…˜ ì´ë¦„ ë° ë²”ìœ„ ì •ë³´
        action_name = f"Action {i+1}"
        action_range = f"[{raw_data.min():.1f}, {raw_data.max():.1f}]"
        
        # ë³€í™”ëŸ‰ í†µê³„
        if f'{action_col}_abs_delta' in df.columns:
            avg_change = df[f'{action_col}_abs_delta'].mean()
            change_info = f", Avg Change: {avg_change:.2f}"
        else:
            change_info = ""
        
        ax.set_title(f'{action_name} Trend - {strategy_name}\n'
                    f'Range: {action_range}{change_info}', 
                    fontsize=11, fontweight='bold')
        ax.set_ylabel(f'{action_name} Value')
        ax.legend(loc='upper left', fontsize=9)
        ax.grid(alpha=0.3)
        
        # í†µê³„ ì •ë³´ í…ìŠ¤íŠ¸ ë°•ìŠ¤
        mean_val = raw_data.mean()
        std_val = raw_data.std()
        
        # íŠ¸ë Œë“œ ë°©í–¥ ê³„ì‚° (ì´ˆê¸° 20% vs ë§ˆì§€ë§‰ 20%)
        early_data = raw_data.head(len(raw_data)//5)
        late_data = raw_data.tail(len(raw_data)//5)
        trend_direction = "â†—" if late_data.mean() > early_data.mean() else "â†˜"
        
        stability = "ì•ˆì •ì " if std_val < mean_val * 0.1 else "ë³€ë™ì "
        
        stats_text = f'Mean: {mean_val:.2f}\nStd: {std_val:.2f}\nTrend: {trend_direction}\n{stability}'
        ax.text(0.98, 0.98, stats_text, transform=ax.transAxes, 
               verticalalignment='top', horizontalalignment='right',
               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),
               fontsize=9)
    
    # ì „ì²´ íƒìƒ‰ í™œë™ë„ ê·¸ë˜í”„ ì¶”ê°€
    if 'exploration_activity' in df.columns:
        ax_explore = axes[-1]
        
        ax_explore.plot(df['step'], df['exploration_activity'], 
                       color='purple', linewidth=2, label='Exploration Activity')
        ax_explore.fill_between(df['step'], df['exploration_activity'], 
                               alpha=0.3, color='purple')
        
        ax_explore.set_title('Overall Exploration Activity', fontsize=11, fontweight='bold')
        ax_explore.set_ylabel('Activity Level')
        ax_explore.set_xlabel('Training Step')
        ax_explore.legend()
        ax_explore.grid(alpha=0.3)
        
        # í•™ìŠµ ë‹¨ê³„ë³„ ë°°ê²½ìƒ‰
        if 'learning_phase' in df.columns and len(df['learning_phase'].unique()) > 1:
            add_phase_backgrounds(ax_explore, df)
    
    plt.tight_layout()
    plt.savefig(output_dir / f"action_trends_{strategy_type}.png", dpi=200, bbox_inches='tight')
    plt.close()

def add_phase_backgrounds(ax, df):
    """í•™ìŠµ ë‹¨ê³„ë³„ ë°°ê²½ìƒ‰ ì¶”ê°€"""
    
    if 'learning_phase_numeric' not in df.columns:
        return
    
    colors = ['#ffebee', '#e8f5e8', '#e3f2fd', '#fff3e0', '#f3e5f5']
    phases = df['learning_phase'].unique()
    
    for i, phase in enumerate(phases):
        if pd.isna(phase):
            continue
            
        phase_data = df[df['learning_phase'] == phase]
        if len(phase_data) > 0:
            start_step = phase_data['step'].min()
            end_step = phase_data['step'].max()
            
            ax.axvspan(start_step, end_step, alpha=0.2, 
                      color=colors[i % len(colors)], label=f'{phase} Phase')

def create_action_exploration_heatmap(df, action_cols, strategy_type, output_dir):
    """ì•¡ì…˜ ê³µê°„ íƒìƒ‰ íˆíŠ¸ë§µ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
    
    # ì •ê·œí™”ëœ ì•¡ì…˜ ë°ì´í„° ì‚¬ìš©
    norm_cols = [f'{col}_normalized' for col in action_cols if f'{col}_normalized' in df.columns]
    
    if len(norm_cols) >= 2:
        # í•™ìŠµ ë‹¨ê³„ë³„ ì„¸ë¶„í™”
        if 'learning_phase' in df.columns and len(df['learning_phase'].unique()) > 1:
            phases = [phase for phase in df['learning_phase'].unique() if pd.notna(phase)]
            n_phases = len(phases)
        else:
            # ìˆ˜ë™ìœ¼ë¡œ ë‹¨ê³„ êµ¬ë¶„
            total_len = len(df)
            phases = ['Early', 'Late']
            phase_data = {
                'Early': df.head(total_len//2),
                'Late': df.tail(total_len//2)
            }
            n_phases = 2
        
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, axes = plt.subplots(1, n_phases, figsize=(6 * n_phases, 6))
        if n_phases == 1:
            axes = [axes]
        
        strategy_name = "MaxMin Strategy" if strategy_type == "maxmin" else "Optimized Strategy"
        
        for i, phase in enumerate(phases):
            ax = axes[i]
            
            # ë‹¨ê³„ë³„ ë°ì´í„° ì¶”ì¶œ
            if 'learning_phase' in df.columns:
                phase_df = df[df['learning_phase'] == phase]
            else:
                phase_df = phase_data[phase]
            
            if len(phase_df) == 0:
                continue
            
            # 2D íˆìŠ¤í† ê·¸ë¨
            x_data = phase_df[norm_cols[0]]
            y_data = phase_df[norm_cols[1]]
            
            # ì•„ì›ƒë¼ì´ì–´ ì œê±° (99% ë¶„ìœ„ìˆ˜ ê¸°ì¤€)
            x_q1, x_q99 = x_data.quantile([0.01, 0.99])
            y_q1, y_q99 = y_data.quantile([0.01, 0.99])
            
            mask = ((x_data >= x_q1) & (x_data <= x_q99) & 
                   (y_data >= y_q1) & (y_data <= y_q99))
            
            x_clean = x_data[mask]
            y_clean = y_data[mask]
            
            # íˆíŠ¸ë§µ ìƒì„±
            h = ax.hist2d(x_clean, y_clean, bins=25, cmap='Blues', alpha=0.8)
            plt.colorbar(h[3], ax=ax, label='Frequency')
            
            ax.set_xlim(-1.1, 1.1)
            ax.set_ylim(-1.1, 1.1)
            ax.set_xlabel(f'{action_cols[0]} (Normalized)')
            ax.set_ylabel(f'{action_cols[1]} (Normalized)')
            ax.set_title(f'{phase} Phase\n({len(phase_df)} samples)')
            ax.grid(alpha=0.3)
            
            # ì¤‘ì‹¬ì  ë° ì‚¬ë¶„ë©´ í‘œì‹œ
            ax.axhline(0, color='red', linestyle='--', alpha=0.7, linewidth=1.5)
            ax.axvline(0, color='red', linestyle='--', alpha=0.7, linewidth=1.5)
            
            # íƒìƒ‰ ë²”ìœ„ í†µê³„ ì¶”ê°€
            x_range = x_clean.max() - x_clean.min()
            y_range = y_clean.max() - y_clean.min()
            coverage = (x_range * y_range) / 4.0  # ì •ê·œí™”ëœ ê³µê°„ì—ì„œì˜ ì»¤ë²„ë¦¬ì§€
            
            stats_text = f'X Range: {x_range:.2f}\nY Range: {y_range:.2f}\nCoverage: {coverage:.2f}'
            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, 
                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        fig.suptitle(f'Action Space Exploration Pattern - {strategy_name}', 
                    fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_dir / f"action_exploration_{strategy_type}.png", dpi=200, bbox_inches='tight')
        plt.close()

def create_action_statistics_plot(df, action_cols, strategy_type, output_dir):
    """ì•¡ì…˜ í†µê³„ ë¶„ì„ í”Œë¡¯ (ê°œì„ ëœ ë²„ì „)"""
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    strategy_name = "MaxMin Strategy" if strategy_type == "maxmin" else "Optimized Strategy"
    
    # 1. ì•¡ì…˜ ë³€ë™ì„± ì¶”ì´ (ê°œì„ ë¨)
    ax1 = axes[0, 0]
    window_size = max(50, len(df) // 30)
    
    for i, action_col in enumerate(action_cols):
        rolling_std = df[action_col].rolling(window=window_size, min_periods=1).std()
        rolling_mean = df[action_col].rolling(window=window_size, min_periods=1).mean()
        cv = rolling_std / (rolling_mean + 1e-8)  # ë³€ë™ê³„ìˆ˜ (Coefficient of Variation)
        
        ax1.plot(df['step'], cv, label=f'Action {i+1} CV', linewidth=2, alpha=0.8)
    
    ax1.set_title('Action Variability (Coefficient of Variation)')
    ax1.set_xlabel('Step')
    ax1.set_ylabel('CV (Std/Mean)')
    ax1.legend()
    ax1.grid(alpha=0.3)
    
    # íƒìƒ‰-í™œìš© ì „í™˜ì  í‘œì‹œ
    if len(action_cols) > 0:
        avg_cv = np.mean([df[col].rolling(window=window_size, min_periods=1).std() / 
                         (df[col].rolling(window=window_size, min_periods=1).mean() + 1e-8) 
                         for col in action_cols], axis=0)
        # CVê°€ ìµœê³ ì ì—ì„œ 50% ê°ì†Œí•œ ì§€ì ì„ ì „í™˜ì ìœ¼ë¡œ ê°„ì£¼
        max_cv_idx = np.argmax(avg_cv)
        transition_threshold = avg_cv[max_cv_idx] * 0.5
        transition_points = np.where(avg_cv[max_cv_idx:] <= transition_threshold)[0]
        if len(transition_points) > 0:
            transition_step = df['step'].iloc[max_cv_idx + transition_points[0]]
            ax1.axvline(transition_step, color='red', linestyle='--', alpha=0.7, 
                       label=f'Exploreâ†’Exploit transition')
            ax1.legend()
    
    # 2. ì•¡ì…˜ë³„ ë¶„í¬ ë¹„êµ (ê°œì„ ë¨)
    ax2 = axes[0, 1]
    
    # ë°”ì´ì˜¬ë¦° í”Œë¡¯ìœ¼ë¡œ ë¶„í¬ í˜•íƒœê¹Œì§€ í‘œì‹œ
    action_data = [df[col] for col in action_cols]
    action_labels = [f'Action {i+1}' for i in range(len(action_cols))]
    
    parts = ax2.violinplot(action_data, showmeans=True, showmedians=True)
    ax2.set_xticks(range(1, len(action_cols) + 1))
    ax2.set_xticklabels(action_labels)
    
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
    for i, pc in enumerate(parts['bodies']):
        pc.set_facecolor(colors[i % len(colors)])
        pc.set_alpha(0.7)
    
    ax2.set_title('Action Value Distribution (Violin Plot)')
    ax2.set_ylabel('Action Value')
    ax2.grid(alpha=0.3)
    
    # ë¶„í¬ í†µê³„ ì¶”ê°€
    for i, (col, data) in enumerate(zip(action_cols, action_data)):
        skewness = data.skew()
        kurtosis = data.kurtosis()
        ax2.text(i+1, data.max(), f'Skew: {skewness:.2f}\nKurt: {kurtosis:.2f}', 
                ha='center', va='bottom', fontsize=8)
    
    # 3. ì•¡ì…˜ ê°„ ìƒê´€ê´€ê³„ (ì‹œê°„ ì§„í™” í¬í•¨)
    ax3 = axes[1, 0]
    if len(action_cols) >= 2:
        # ì‹œê°„ êµ¬ê°„ë³„ ìƒê´€ê´€ê³„ ë³€í™”
        n_segments = 5
        segment_size = len(df) // n_segments
        correlations_over_time = []
        
        for i in range(n_segments):
            start_idx = i * segment_size
            end_idx = (i + 1) * segment_size if i < n_segments - 1 else len(df)
            segment_df = df.iloc[start_idx:end_idx]
            
            if len(segment_df) > 1:
                corr = segment_df[action_cols[0]].corr(segment_df[action_cols[1]])
                correlations_over_time.append(corr)
            else:
                correlations_over_time.append(0)
        
        # ìƒê´€ê´€ê³„ ë³€í™” í”Œë¡¯
        segment_steps = [df['step'].iloc[i * segment_size] for i in range(n_segments)]
        ax3.plot(segment_steps, correlations_over_time, 'o-', linewidth=2, markersize=8)
        ax3.set_xlabel('Training Step')
        ax3.set_ylabel(f'Correlation ({action_cols[0]} vs {action_cols[1]})')
        ax3.set_title('Action Correlation Evolution')
        ax3.grid(alpha=0.3)
        ax3.axhline(0, color='red', linestyle='--', alpha=0.5)
        
        # ìµœì¢… ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ (ì¸ì…‹)
        if len(action_cols) > 2:
            from mpl_toolkits.axes_grid1.inset_locator import inset_axes
            axins = inset_axes(ax3, width="40%", height="40%", loc='upper right')
            
            final_corr = df[action_cols].corr()
            im = axins.imshow(final_corr, cmap='RdBu_r', vmin=-1, vmax=1)
            axins.set_xticks(range(len(action_cols)))
            axins.set_yticks(range(len(action_cols)))
            axins.set_xticklabels([f'A{i+1}' for i in range(len(action_cols))], fontsize=8)
            axins.set_yticklabels([f'A{i+1}' for i in range(len(action_cols))], fontsize=8)
            axins.set_title('Final Correlation', fontsize=10)
    
    # 4. í•™ìŠµ ë‹¨ê³„ë³„ ì•¡ì…˜ íŠ¹ì„± (ê°œì„ ë¨)
    ax4 = axes[1, 1]
    if 'learning_phase' in df.columns and len(df['learning_phase'].unique()) > 1:
        phases = [phase for phase in df['learning_phase'].unique() if pd.notna(phase)]
        
        # ê° ë‹¨ê³„ë³„ ì•¡ì…˜ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨
        phase_stats = {}
        for phase in phases:
            phase_data = df[df['learning_phase'] == phase]
            means = [phase_data[col].mean() for col in action_cols]
            stds = [phase_data[col].std() for col in action_cols]
            phase_stats[phase] = {'means': means, 'stds': stds}
        
        x = np.arange(len(action_cols))
        width = 0.8 / len(phases)
        
        for i, phase in enumerate(phases):
            means = phase_stats[phase]['means']
            stds = phase_stats[phase]['stds']
            
            bars = ax4.bar(x + i * width, means, width, 
                          yerr=stds, label=f'{phase} Phase', 
                          alpha=0.8, capsize=5)
        
        ax4.set_title('Action Statistics by Learning Phase')
        ax4.set_xlabel('Actions')
        ax4.set_ylabel('Value (Mean Â± Std)')
        ax4.set_xticks(x + width * (len(phases) - 1) / 2)
        ax4.set_xticklabels([f'Action {i+1}' for i in range(len(action_cols))])
        ax4.legend()
        ax4.grid(alpha=0.3)
    
    fig.suptitle(f'Comprehensive Action Analysis - {strategy_name}', 
                fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / f"action_statistics_{strategy_type}.png", dpi=200, bbox_inches='tight')
    plt.close()

def create_action_reward_correlation(df, action_cols, strategy_type, output_dir):
    """ì•¡ì…˜-ë³´ìƒ ìƒê´€ê´€ê³„ ë¶„ì„ (ê°œì„ ëœ ë²„ì „)"""
    
    n_actions = len(action_cols)
    fig, axes = plt.subplots(2, n_actions, figsize=(5 * n_actions, 10))
    if n_actions == 1:
        axes = axes.reshape(2, 1)
    
    strategy_name = "MaxMin Strategy" if strategy_type == "maxmin" else "Optimized Strategy"
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFA07A', '#98D8C8']
    
    for i, action_col in enumerate(action_cols):
        # ìƒë‹¨: ì‚°ì ë„ (ì‹œê°„ ì§„í–‰ë³„ ìƒ‰ìƒ)
        ax1 = axes[0, i]
        
        # ì•„ì›ƒë¼ì´ì–´ ì œê±°
        action_data = df[action_col]
        reward_data = df['reward']
        
        # 99% ë¶„ìœ„ìˆ˜ ê¸°ì¤€ í•„í„°ë§
        action_q1, action_q99 = action_data.quantile([0.01, 0.99])
        reward_q1, reward_q99 = reward_data.quantile([0.01, 0.99])
        
        mask = ((action_data >= action_q1) & (action_data <= action_q99) & 
               (reward_data >= reward_q1) & (reward_data <= reward_q99))
        
        clean_action = action_data[mask]
        clean_reward = reward_data[mask]
        clean_steps = df['step'][mask]
        
        # ì‚°ì ë„
        scatter = ax1.scatter(clean_action, clean_reward, c=clean_steps, 
                             cmap='viridis', alpha=0.6, s=15)
        
        # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        correlation = clean_action.corr(clean_reward)
        
        # ì¶”ì„¸ì„  (ë¡œë²„ìŠ¤íŠ¸ íšŒê·€)
        from scipy import stats
        slope, intercept, r_value, p_value, std_err = stats.linregress(clean_action, clean_reward)
        line_x = np.array([clean_action.min(), clean_action.max()])
        line_y = slope * line_x + intercept
        
        ax1.plot(line_x, line_y, "r-", alpha=0.8, linewidth=2.5, 
                label=f'R={correlation:.3f}, p={p_value:.3f}')
        
        ax1.set_xlabel(f'{action_col} Value')
        ax1.set_ylabel('Reward')
        ax1.set_title(f'Action {i+1} vs Reward')
        ax1.grid(alpha=0.3)
        ax1.legend()
        
        # ì»¬ëŸ¬ë°” (ë§ˆì§€ë§‰ ì•¡ì…˜ì—ë§Œ)
        if i == len(action_cols) - 1:
            plt.colorbar(scatter, ax=ax1, label='Training Step')
        
        # í•˜ë‹¨: ì‹œê°„ì— ë”°ë¥¸ ìƒê´€ê´€ê³„ ë³€í™”
        ax2 = axes[1, i]
        
        # ì´ë™ ìœˆë„ìš° ìƒê´€ê´€ê³„ ê³„ì‚°
        window_size = max(100, len(df) // 20)
        rolling_corr = clean_action.rolling(window=window_size, min_periods=window_size//2).corr(clean_reward)
        
        ax2.plot(clean_steps, rolling_corr, color=colors[i % len(colors)], linewidth=2)
        ax2.fill_between(clean_steps, rolling_corr, alpha=0.3, color=colors[i % len(colors)])
        
        ax2.set_xlabel('Training Step')
        ax2.set_ylabel('Rolling Correlation')
        ax2.set_title(f'Action {i+1} Correlation Evolution')
        ax2.grid(alpha=0.3)
        ax2.axhline(0, color='red', linestyle='--', alpha=0.5)
        
        # ìƒê´€ê´€ê³„ ê°•ë„ë³„ êµ¬ê°„ í‘œì‹œ
        strong_positive = rolling_corr > 0.3
        strong_negative = rolling_corr < -0.3
        
        ax2.fill_between(clean_steps, rolling_corr, 0, where=strong_positive, 
                        color='green', alpha=0.2, label='Strong Positive')
        ax2.fill_between(clean_steps, rolling_corr, 0, where=strong_negative, 
                        color='red', alpha=0.2, label='Strong Negative')
        
        if strong_positive.any() or strong_negative.any():
            ax2.legend()
        
        # í†µê³„ ì •ë³´ ì¶”ê°€
        final_corr = rolling_corr.iloc[-window_size:].mean() if len(rolling_corr) >= window_size else correlation
        corr_std = rolling_corr.std()
        
        stats_text = f'Final Corr: {final_corr:.3f}\nStd: {corr_std:.3f}'
        ax2.text(0.02, 0.98, stats_text, transform=ax2.transAxes, 
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    fig.suptitle(f'Action-Reward Relationship Analysis - {strategy_name}', 
                fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / f"action_reward_correlation_{strategy_type}.png", dpi=200, bbox_inches='tight')
    plt.close()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ë³´ê³ ì„œ ìƒì„± (ê°œì„ ëœ ë²„ì „)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_action_patterns(df, action_cols, strategy_type):
    """ì•¡ì…˜ íŒ¨í„´ ë¶„ì„ ë° ìš”ì•½ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
    
    total_steps = int(df['step'].max() - df['step'].min())
    total_samples = len(df)
    
    # íƒìƒ‰ í™œë™ë„ ë¶„ì„
    if 'exploration_activity' in df.columns:
        early_exploration = df['exploration_activity'].head(len(df)//3).mean()
        late_exploration = df['exploration_activity'].tail(len(df)//3).mean()
        exploration_decay = (early_exploration - late_exploration) / early_exploration if early_exploration > 0 else 0
        
        exploration_analysis = f"""
íƒìƒ‰ í™œë™ë„ê°€ ì´ˆê¸° {early_exploration:.3f}ì—ì„œ í›„ê¸° {late_exploration:.3f}ë¡œ ë³€í™”í–ˆìŠµë‹ˆë‹¤ ({exploration_decay*100:.1f}% ê°ì†Œ).
ì´ëŠ” {"ì ì ˆí•œ íƒìƒ‰ì—ì„œ í™œìš©ìœ¼ë¡œì˜ ì „í™˜" if exploration_decay > 0.2 else "ì§€ì†ì ì¸ íƒìƒ‰ í–‰ë™"}ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""
    else:
        # ì•¡ì…˜ ë³€í™”ëŸ‰ ê¸°ë°˜ ë¶„ì„
        if len(action_cols) >= 2:
            action1_range = df[action_cols[0]].max() - df[action_cols[0]].min()
            action2_range = df[action_cols[1]].max() - df[action_cols[1]].min()
            exploration_diversity = (action1_range + action2_range) / 2
            
            if strategy_type == "maxmin":
                exploration_analysis = f"ë„“ì€ íƒìƒ‰ ë²”ìœ„(í‰ê·  {exploration_diversity:.2f})ë¥¼ ë³´ì´ë©°, ê·¹ê°’ ì¶”êµ¬ íŠ¹ì„±ì— ë”°ë¼ ì•¡ì…˜ ê³µê°„ì˜ ê²½ê³„ ì˜ì—­ì„ ì ê·¹ì ìœ¼ë¡œ íƒìƒ‰í–ˆìŠµë‹ˆë‹¤."
            else:
                exploration_analysis = f"ì•ˆì •ì ì¸ íƒìƒ‰ ë²”ìœ„(í‰ê·  {exploration_diversity:.2f})ë¥¼ ë³´ì´ë©°, ìµœì  ë²”ìœ„ ë‚´ì—ì„œ ì§‘ì¤‘ì ì¸ íƒìƒ‰ì´ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤."
        else:
            exploration_analysis = "ë‹¨ì¼ ì•¡ì…˜ìœ¼ë¡œ ì¸í•´ ì œí•œì  ë¶„ì„ì´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    # ìƒê´€ê´€ê³„ ë¶„ì„ (ê°œì„ ë¨)
    if len(action_cols) >= 2:
        corr_matrix = df[action_cols].corr()
        max_corr = corr_matrix.abs().values[np.triu_indices_from(corr_matrix.values, k=1)].max()
        
        # ì‹œê°„ë³„ ìƒê´€ê´€ê³„ ë³€í™” ë¶„ì„
        early_corr = df[action_cols].head(len(df)//3).corr()
        late_corr = df[action_cols].tail(len(df)//3).corr()
        
        early_max = early_corr.abs().values[np.triu_indices_from(early_corr.values, k=1)].max()
        late_max = late_corr.abs().values[np.triu_indices_from(late_corr.values, k=1)].max()
        
        correlation_analysis = f"""
ì•¡ì…˜ ê°„ ìƒê´€ê´€ê³„ê°€ ì´ˆê¸° {early_max:.3f}ì—ì„œ í›„ê¸° {late_max:.3f}ë¡œ ë³€í™”í–ˆìŠµë‹ˆë‹¤.
{"ìƒê´€ê´€ê³„ê°€ ê°•í™”ë˜ì–´" if late_max > early_max else "ìƒê´€ê´€ê³„ê°€ ì•½í™”ë˜ì–´"} 
{"í˜‘ë ¥ì  ì•¡ì…˜ íŒ¨í„´" if late_max > 0.5 else "ë…ë¦½ì  ì•¡ì…˜ íŒ¨í„´"}ì„ ë³´ì…ë‹ˆë‹¤.
"""
    else:
        correlation_analysis = "ë‹¨ì¼ ì•¡ì…˜ìœ¼ë¡œ ì¸í•´ ìƒê´€ê´€ê³„ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
    
    # ì„±ê³¼ ê¸°ì—¬ë„ ë¶„ì„ (ê°œì„ ë¨)
    action_reward_corrs = [df[col].corr(df['reward']) for col in action_cols]
    best_action_idx = np.argmax(np.abs(action_reward_corrs))
    best_corr = action_reward_corrs[best_action_idx]
    
    # ì‹œê°„ë³„ ìƒê´€ê´€ê³„ ë³€í™”
    early_corrs = [df[col].head(len(df)//3).corr(df['reward'].head(len(df)//3)) for col in action_cols]
    late_corrs = [df[col].tail(len(df)//3).corr(df['reward'].tail(len(df)//3)) for col in action_cols]
    
    performance_analysis = f"""
Action {best_action_idx + 1}ì´ ë³´ìƒê³¼ ê°€ì¥ ê°•í•œ ìƒê´€ê´€ê³„({best_corr:.3f})ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
í•™ìŠµ ì´ˆê¸°ì™€ í›„ê¸° ìƒê´€ê´€ê³„ ë³€í™”ë¥¼ ë³´ë©´, 
{f"ëŒ€ë¶€ë¶„ ì•¡ì…˜ì˜ ì„±ê³¼ ê¸°ì—¬ë„ê°€ ì¦ê°€" if np.mean(late_corrs) > np.mean(early_corrs) else "ì•¡ì…˜ íš¨ê³¼ì„±ì´ ì•ˆì •í™”"}ë˜ì—ˆìŠµë‹ˆë‹¤.
"""
    
    # í•µì‹¬ ë°œê²¬ì‚¬í•­ (ì „ëµë³„ ë§ì¶¤í™”)
    if strategy_type == "maxmin":
        # ë³€ë™ì„± ë¶„ì„
        avg_cv = np.mean([df[col].std() / df[col].mean() for col in action_cols])
        
        key_findings = f"""
1. **ì ê·¹ì  íƒìƒ‰**: í‰ê·  ë³€ë™ê³„ìˆ˜ {avg_cv:.3f}ë¡œ ë²•ì  ê²½ê³„ ê·¼ì²˜ì—ì„œì˜ í™œë°œí•œ ì•¡ì…˜ ë³€í™” í™•ì¸
2. **ë†’ì€ ë³€ë™ì„±**: í˜ì‹ ì  ì†”ë£¨ì…˜ íƒìƒ‰ ê³¼ì •ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë³€ë™ì„±
3. **í•™ìŠµ ì§„í™”**: ì´ˆê¸° ë¬´ì‘ìœ„ íƒìƒ‰ì—ì„œ í›„ê¸° ëª©ì ì„± ìˆëŠ” íƒìƒ‰ìœ¼ë¡œ ì§„í™”
4. **ê²½ê³„ íƒìƒ‰**: ê·¹ê°’ ì¶”êµ¬ë¡œ ì¸í•œ ì•¡ì…˜ ê³µê°„ì˜ ê²½ê³„ ì˜ì—­ ì§‘ì¤‘ íƒìƒ‰
"""
    else:
        # ì•ˆì •ì„± ë¶„ì„
        avg_cv = np.mean([df[col].std() / df[col].mean() for col in action_cols])
        
        key_findings = f"""
1. **ì•ˆì •ì  ìˆ˜ë ´**: í‰ê·  ë³€ë™ê³„ìˆ˜ {avg_cv:.3f}ë¡œ ìµœì  ë²”ìœ„ë¡œì˜ ì ì§„ì  ìˆ˜ë ´ í™•ì¸
2. **ì˜ˆì¸¡ ê°€ëŠ¥ì„±**: ì¼ê´€ëœ ì•¡ì…˜ ì„ íƒìœ¼ë¡œ ë†’ì€ ì¬í˜„ì„± í™•ë³´
3. **íš¨ìœ¨ì  í•™ìŠµ**: ë¶ˆí•„ìš”í•œ íƒìƒ‰ ì—†ì´ ëª©í‘œ ì§€í–¥ì  í•™ìŠµ ìˆ˜í–‰
4. **ë²”ìœ„ ì¤€ìˆ˜**: ê²€ì¦ëœ ìµœì  ë²”ìœ„ ë‚´ì—ì„œì˜ ì§‘ì¤‘ì  íƒìƒ‰
"""
    
    # ì‹¤ë¬´ ì ìš© ì‹œì‚¬ì  (ìƒí™©ë³„ ì„¸ë¶„í™”)
    if strategy_type == "maxmin":
        practical_implications = f"""
- **í˜ì‹  í”„ë¡œì íŠ¸**: ì°½ì˜ì  ì†”ë£¨ì…˜ ë°œê²¬ì— íš¨ê³¼ì , íƒìƒ‰ ë‹¤ì–‘ì„± {exploration_diversity:.2f}
- **ì‹¤í—˜ì  ì„¤ê³„**: ì¶©ë¶„í•œ íƒìƒ‰ ì‹œê°„ê³¼ ì‹¤í—˜ ì—¬ìœ ê°€ ìˆëŠ” í”„ë¡œì íŠ¸ì— ì í•©
- **ìœ„í—˜ ê´€ë¦¬**: ê²°ê³¼ ë³€ë™ì„±({avg_cv:.3f})ì„ ê°ì•ˆí•œ ì—¬ëŸ¬ ëŒ€ì•ˆ ê²€í†  í•„ìš”
- **í˜ì‹  vs ì•ˆì •ì„±**: íšê¸°ì  ê°œì„  ê°€ëŠ¥ì„±ê³¼ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥ì„±ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„
"""
    else:
        practical_implications = f"""
- **ìƒì—… í”„ë¡œì íŠ¸**: ì•ˆì •ì„±({avg_cv:.3f})ê³¼ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì´ ì¤‘ìš”í•œ ì‹¤ë¬´ì— ì í•©
- **ì¦‰ì‹œ ì ìš©**: ê²€ì¦ëœ ë²”ìœ„ ë‚´ ì†”ë£¨ì…˜ìœ¼ë¡œ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê²°ê³¼ ì œê³µ
- **ìœ„í—˜ ìµœì†Œí™”**: ë‚®ì€ ë³€ë™ì„±ìœ¼ë¡œ ìœ„í—˜ ê´€ë¦¬ê°€ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ì— ì„ í˜¸
- **íš¨ìœ¨ì„±**: íƒìƒ‰ ëŒ€ë¹„ í™œìš© ë¹„ìœ¨ì´ ë†’ì•„ ì‹œê°„ íš¨ìœ¨ì  ì ‘ê·¼ë²•
"""
    
    # ê°œì„  ë°©í–¥ (êµ¬ì²´ì  ì œì•ˆ)
    improvement_suggestions = f"""
1. **í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**: 
   - ì´ˆê¸°ì—” MaxMin ë°©ì‹ìœ¼ë¡œ ë„“ì€ íƒìƒ‰, í›„ê¸°ì—” Optimized ë°©ì‹ìœ¼ë¡œ ì„¸ë°€ ì¡°ì •
   - íƒìƒ‰-í™œìš© ê· í˜•ì ì„ ë™ì ìœ¼ë¡œ ì¡°ì ˆí•˜ëŠ” ì ì‘ì  ì „ëµ

2. **ìƒí™©ë³„ ìµœì í™”**:
   - í”„ë¡œì íŠ¸ ìœ„í—˜ë„ì— ë”°ë¥¸ íƒìƒ‰ ê°•ë„ ì¡°ì ˆ
   - ì‹œê°„ ì œì•½ì— ë”°ë¥¸ ì „ëµ ì„ íƒ ê°€ì´ë“œë¼ì¸

3. **ì„±ê³¼ ê¸°ë°˜ ì¡°ì •**:
   - ì‹¤ì‹œê°„ ì„±ê³¼ í”¼ë“œë°±ì„ í†µí•œ ì•¡ì…˜ ê³µê°„ ë™ì  ì¡°ì •
   - ìƒê´€ê´€ê³„ ë³€í™” íŒ¨í„´ì„ í™œìš©í•œ ì˜ˆì¸¡ì  ì•¡ì…˜ ê°€ì¤‘ì¹˜ ì¡°ì ˆ

4. **ë©€í‹°ëª¨ë‹¬ íƒìƒ‰**:
   - ì—¬ëŸ¬ ìµœì í•´ í›„ë³´ë¥¼ ë™ì‹œ íƒìƒ‰í•˜ëŠ” ì•™ìƒë¸” ì ‘ê·¼ë²•
   - ë‹¤ì–‘í•œ ì„¤ê³„ ì œì•½ ì¡°ê±´ì— ëŒ€í•œ ê°•ê±´ì„± í™•ë³´
"""
    
    return {
        'total_steps': total_steps,
        'total_samples': total_samples,
        'exploration_analysis': exploration_analysis.strip(),
        'correlation_analysis': correlation_analysis.strip(),
        'performance_analysis': performance_analysis.strip(),
        'key_findings': key_findings.strip(),
        'practical_implications': practical_implications.strip(),
        'improvement_suggestions': improvement_suggestions.strip()
    }

def generate_action_analysis_report(df, action_cols, strategy_type, output_dir, analysis_summary):
    """ì•¡ì…˜ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
    
    strategy_names = {
        "maxmin": "MaxMin ë°©í–¥ì„± ì „ëµ",
        "optimized": "Optimized ë²”ìœ„ ê¸°ë°˜ ì „ëµ"
    }
    
    strategy_name_kr = strategy_names.get(strategy_type, strategy_type)
    strategy_name_en = "MaxMin Strategy" if strategy_type == "maxmin" else "Optimized Strategy"
    
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')
    
    # ë°ì´í„° í’ˆì§ˆ ì •ë³´ ì¶”ê°€
    data_quality_info = f"""
### ë°ì´í„° í’ˆì§ˆ ì •ë³´
- **ì›ë³¸ ë°ì´í„°**: í•„í„°ë§ ì „ ì •ë³´ (ë¡œê·¸ì—ì„œ í™•ì¸)
- **ìœ íš¨ ë°ì´í„°**: {analysis_summary['total_samples']:,}ê°œ ìƒ˜í”Œ
- **í•™ìŠµ ê¸°ê°„**: {analysis_summary['total_steps']:,} ìŠ¤í…
- **ì´ˆê¸°í™” í•„í„°ë§**: ë°˜ë³µëœ ì´ˆê¸° ì•¡ì…˜ ê°’ ì œê±° ì™„ë£Œ
- **ì•„ì›ƒë¼ì´ì–´ ì œê±°**: 99% ë¶„ìœ„ìˆ˜ ê¸°ì¤€ ê·¹ê°’ ì œê±° ì ìš©
"""
    
    report_md = f"""# ì•¡ì…˜ ë³€í™” ì¶”ì´ ë¶„ì„ ë³´ê³ ì„œ - {strategy_name_kr}

## 1. ë¶„ì„ ê°œìš”

- **ë¶„ì„ ë‚ ì§œ**: {timestamp}
- **ì „ëµ ìœ í˜•**: {strategy_name_kr} ({strategy_name_en})
- **ì´ ìŠ¤í… ìˆ˜**: {analysis_summary['total_steps']:,}
- **ë¶„ì„ ìƒ˜í”Œ ìˆ˜**: {analysis_summary['total_samples']:,}
- **ì•¡ì…˜ ì°¨ì›**: {len(action_cols)}ê°œ

{data_quality_info}

## 2. ì•¡ì…˜ ë³€í™” ì¶”ì´ ë¶„ì„

![Action Trends](./action_trends_{strategy_type}.png)

*ìœ„ ê·¸ë˜í”„ëŠ” í•™ìŠµ ê³¼ì •ì—ì„œ ê° ì•¡ì…˜ ê°’ì˜ ë³€í™” ì¶”ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íšŒìƒ‰ ì„ ì€ ì›ë³¸ ë°ì´í„°, ìƒ‰ìƒ ì„ ì€ ìŠ¤ë¬´ë”©ëœ ì¶”ì´, ì ì„ ì€ ì •ê·œí™”ëœ ê°’(-1~1)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.*

### 2.1 ì£¼ìš” ë°œê²¬ì‚¬í•­

"""
    
    # ì•¡ì…˜ë³„ í†µê³„ ë¶„ì„ (ê°œì„ ë¨)
    for i, action_col in enumerate(action_cols):
        action_data = df[action_col]
        mean_val = action_data.mean()
        std_val = action_data.std()
        cv = std_val / mean_val if mean_val != 0 else 0
        
        # íŠ¸ë Œë“œ ë¶„ì„ (ê°œì„ ë¨)
        early_data = action_data.head(len(action_data)//5)
        late_data = action_data.tail(len(action_data)//5)
        trend_change = (late_data.mean() - early_data.mean()) / early_data.mean() * 100 if early_data.mean() != 0 else 0
        trend_direction = "ìƒìŠ¹" if trend_change > 5 else "í•˜ë½" if trend_change < -5 else "ì•ˆì •"
        
        # ë³€ë™ì„± íŠ¹ì„±
        stability = "ë§¤ìš° ì•ˆì •" if cv < 0.05 else "ì•ˆì •ì " if cv < 0.15 else "ë³€ë™ì " if cv < 0.3 else "ë§¤ìš° ë³€ë™ì "
        
        # ë¶„í¬ íŠ¹ì„±
        skewness = action_data.skew()
        kurtosis = action_data.kurtosis()
        distribution_shape = "ì •ê·œë¶„í¬" if abs(skewness) < 0.5 and abs(kurtosis) < 3 else "ë¹„ëŒ€ì¹­ë¶„í¬" if abs(skewness) > 1 else "ì¹˜ìš°ì¹œë¶„í¬"
        
        report_md += f"""
#### Action {i+1} ì„¸ë¶€ ë¶„ì„
- **í†µê³„**: í‰ê·  {mean_val:.2f}, í‘œì¤€í¸ì°¨ {std_val:.2f}, ë³€ë™ê³„ìˆ˜ {cv:.3f}
- **ë²”ìœ„**: [{action_data.min():.2f}, {action_data.max():.2f}]
- **ë³€í™” ê²½í–¥**: {trend_direction} ({trend_change:+.1f}%)
- **ì•ˆì •ì„±**: {stability}
- **ë¶„í¬ íŠ¹ì„±**: {distribution_shape} (ì™œë„: {skewness:.2f}, ì²¨ë„: {kurtosis:.2f})
"""
    
    # ì „ëµë³„ í•´ì„ ì¶”ê°€ (ê°œì„ ë¨)
    if strategy_type == "maxmin":
        strategy_interpretation = f"""
### 2.2 MaxMin ì „ëµ íŠ¹ì„± í•´ì„

MaxMin ë°©í–¥ì„± ì „ëµì—ì„œì˜ ì•¡ì…˜ ë³€í™”ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ë³´ì…ë‹ˆë‹¤:

{analysis_summary['exploration_analysis']}

**ì „ëµì  í•¨ì˜:**
- í˜ì‹ ì  ì„¤ê³„ ì†”ë£¨ì…˜ íƒìƒ‰ì„ ìœ„í•œ ì ê·¹ì  ì•¡ì…˜ ê³µê°„ íƒìƒ‰
- ë²•ì  ì œí•œê³¼ ì„±ê³¼ ê°„ì˜ ìµœì  ê· í˜•ì  ë°œê²¬ ê³¼ì •
- ê¸°ì¡´ ê´€ë¡€ë¥¼ ë²—ì–´ë‚œ ì°½ì˜ì  íŒŒë¼ë¯¸í„° ì¡°í•© ì‹œë„

**í•™ìŠµ íŒ¨í„´:**
- ì´ˆê¸°: ê´‘ë²”ìœ„í•œ íƒìƒ‰ìœ¼ë¡œ ê°€ëŠ¥ì„± ê³µê°„ íŒŒì•…
- ì¤‘ê¸°: ìœ ë§í•œ ì˜ì—­ì—ì„œì˜ ì§‘ì¤‘ì  íƒìƒ‰
- í›„ê¸°: ê·¹ê°’ ê·¼ì²˜ì—ì„œì˜ ì„¸ë°€í•œ ì¡°ì •
"""
    else:
        strategy_interpretation = f"""
### 2.2 Optimized ì „ëµ íŠ¹ì„± í•´ì„

Optimized ë²”ìœ„ ê¸°ë°˜ ì „ëµì—ì„œì˜ ì•¡ì…˜ ë³€í™”ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ë³´ì…ë‹ˆë‹¤:

{analysis_summary['exploration_analysis']}

**ì „ëµì  í•¨ì˜:**
- ê²€ì¦ëœ ìµœì  ë²”ìœ„ë¡œì˜ íš¨ìœ¨ì ì´ê³  ì•ˆì •ì ì¸ ìˆ˜ë ´
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì„±ê³¼ë¥¼ ìœ„í•œ ì²´ê³„ì  ì•¡ì…˜ ì„ íƒ
- ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±ì´ ë†’ì€ ë³´ìˆ˜ì  íƒìƒ‰ ì „ëµ

**í•™ìŠµ íŒ¨í„´:**
- ì´ˆê¸°: ìµœì  ë²”ìœ„ ê²½ê³„ í™•ì¸
- ì¤‘ê¸°: ë²”ìœ„ ë‚´ì—ì„œì˜ ì„¸ë°€í•œ ì¡°ì •
- í›„ê¸°: ìµœì ì  ì£¼ë³€ì—ì„œì˜ ì•ˆì •í™”
"""
    
    report_md += strategy_interpretation
    
    report_md += f"""

## 3. ì•¡ì…˜ ê³µê°„ íƒìƒ‰ íŒ¨í„´

![Action Exploration](./action_exploration_{strategy_type}.png)

*ìœ„ íˆíŠ¸ë§µì€ í•™ìŠµ ë‹¨ê³„ë³„ ì•¡ì…˜ ê³µê°„ íƒìƒ‰ íŒ¨í„´ì„ ë¹„êµí•©ë‹ˆë‹¤. ìƒ‰ìƒì´ ì§„í• ìˆ˜ë¡ í•´ë‹¹ ì•¡ì…˜ ì¡°í•©ì„ ë” ìì£¼ ì„ íƒí–ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.*

### 3.1 íƒìƒ‰ ì „ëµ ë¶„ì„

{analysis_summary['exploration_analysis']}

### 3.2 ê³µê°„ ì»¤ë²„ë¦¬ì§€ íŠ¹ì„±

- **íƒìƒ‰ ë²”ìœ„**: ì •ê·œí™”ëœ ì•¡ì…˜ ê³µê°„ì—ì„œì˜ ì‹¤ì œ íƒìƒ‰ ì˜ì—­
- **ì§‘ì¤‘ë„**: íŠ¹ì • ì•¡ì…˜ ì¡°í•©ì— ëŒ€í•œ ì„ í˜¸ë„ íŒ¨í„´
- **ì§„í™”**: í•™ìŠµ ì§„í–‰ì— ë”°ë¥¸ íƒìƒ‰ íŒ¨í„´ì˜ ë³€í™”

## 4. ì¢…í•© ì•¡ì…˜ í†µê³„ ë¶„ì„

![Action Statistics](./action_statistics_{strategy_type}.png)

*ìœ„ ê·¸ë˜í”„ëŠ” ì•¡ì…˜ì˜ ë³€ë™ì„±, ë¶„í¬, ìƒê´€ê´€ê³„, í•™ìŠµ ë‹¨ê³„ë³„ ë³€í™”ë¥¼ ì¢…í•© ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.*

### 4.1 ì•¡ì…˜ ë³€ë™ì„± ë¶„ì„

- **ë³€ë™ê³„ìˆ˜ ì¶”ì´**: í•™ìŠµ ì§„í–‰ì— ë”°ë¥¸ íƒìƒ‰-í™œìš© ì „í™˜ íŒ¨í„´
- **ì•ˆì •í™” ì§€ì **: íƒìƒ‰ì—ì„œ í™œìš©ìœ¼ë¡œ ì „í™˜ë˜ëŠ” ì„ê³„ì  ì‹ë³„
- **ë¶„í¬ íŠ¹ì„±**: ê° ì•¡ì…˜ì˜ ê°’ ë¶„í¬ í˜•íƒœì™€ ì„ í˜¸ êµ¬ê°„

### 4.2 ì•¡ì…˜ ê°„ ìƒê´€ê´€ê³„

{analysis_summary['correlation_analysis']}

**ìƒê´€ê´€ê³„ í•´ì„:**
- ë†’ì€ ìƒê´€ê´€ê³„ (>0.7): ì•¡ì…˜ë“¤ì´ í˜‘ë ¥ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” íŒ¨í„´
- ì¤‘ê°„ ìƒê´€ê´€ê³„ (0.3-0.7): ë¶€ë¶„ì  ì—°ê´€ì„±ì„ ê°€ì§„ ë…ë¦½ì  ì‘ë™
- ë‚®ì€ ìƒê´€ê´€ê³„ (<0.3): ê° ì•¡ì…˜ì´ ë…ë¦½ì ìœ¼ë¡œ ê¸°ëŠ¥

### 4.3 í•™ìŠµ ë‹¨ê³„ë³„ íŠ¹ì„± ë³€í™”

í•™ìŠµ ì§„í–‰ì— ë”°ë¥¸ ì•¡ì…˜ ì„ íƒ íŒ¨í„´ì˜ ì§„í™”ë¥¼ ë¶„ì„í•˜ì—¬ ì „ëµì˜ íš¨ê³¼ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.

## 5. ì•¡ì…˜-ë³´ìƒ ìƒê´€ê´€ê³„ ì‹¬ì¸µ ë¶„ì„

![Action-Reward Correlation](./action_reward_correlation_{strategy_type}.png)

*ìœ„ ê·¸ë˜í”„ëŠ” ê° ì•¡ì…˜ê³¼ ë³´ìƒ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ì‹œê°„ ìˆœì„œì™€ í•¨ê»˜ ë³´ì—¬ì¤ë‹ˆë‹¤. ìƒë‹¨ì€ ì „ì²´ ìƒê´€ê´€ê³„, í•˜ë‹¨ì€ ì‹œê°„ì— ë”°ë¥¸ ìƒê´€ê´€ê³„ ë³€í™”ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.*

### 5.1 ì„±ê³¼ ê¸°ì—¬ë„ ë¶„ì„

{analysis_summary['performance_analysis']}

### 5.2 í•™ìŠµ ì§„í™” íŒ¨í„´

- **ì´ˆê¸° ë‹¨ê³„**: ë¬´ì‘ìœ„ íƒìƒ‰ìœ¼ë¡œ ì¸í•œ ë‚®ì€ ìƒê´€ê´€ê³„
- **ì¤‘ê°„ ë‹¨ê³„**: íŒ¨í„´ í•™ìŠµìœ¼ë¡œ ìƒê´€ê´€ê³„ ê°•í™”
- **í›„ê¸° ë‹¨ê³„**: ìµœì í™”ëœ ì•¡ì…˜-ë³´ìƒ ê´€ê³„ ì•ˆì •í™”

## 6. ì „ëµë³„ ì„±ëŠ¥ ë¹„êµ ë° ì¸ì‚¬ì´íŠ¸

### 6.1 í•µì‹¬ ë°œê²¬ì‚¬í•­

{analysis_summary['key_findings']}

### 6.2 ì‹¤ë¬´ ì ìš© ì‹œì‚¬ì 

{analysis_summary['practical_implications']}

### 6.3 ì „ëµ ì„ íƒ ê°€ì´ë“œë¼ì¸

#### MaxMin ì „ëµì´ ì í•©í•œ ê²½ìš°:
- í˜ì‹ ì  ëŒíŒŒêµ¬ê°€ í•„ìš”í•œ í”„ë¡œì íŠ¸
- íƒìƒ‰ ì‹œê°„ê³¼ ì‹¤í—˜ ë¹„ìš©ì— ì—¬ìœ ê°€ ìˆëŠ” ìƒí™©
- ê¸°ì¡´ ê´€ë¡€ì—ì„œ ë²—ì–´ë‚œ ì°½ì˜ì  ì†”ë£¨ì…˜ í•„ìš”
- ì¥ê¸°ì  ê´€ì ì—ì„œ ìµœì í•´ ë°œê²¬ì´ ì¤‘ìš”í•œ ê²½ìš°

#### Optimized ì „ëµì´ ì í•©í•œ ê²½ìš°:
- ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²°ê³¼ê°€ í•„ìš”í•œ ìƒì—… í”„ë¡œì íŠ¸
- ì‹œê°„ê³¼ ë¹„ìš© ì œì•½ì´ ì—„ê²©í•œ ìƒí™©
- ìœ„í—˜ ê´€ë¦¬ê°€ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸
- ê²€ì¦ëœ ë²”ìœ„ ë‚´ì—ì„œì˜ ìµœì í™”ê°€ ëª©í‘œì¸ ê²½ìš°

## 7. í–¥í›„ ê°œì„  ë° ì—°êµ¬ ë°©í–¥

### 7.1 ë‹¨ê¸° ê°œì„  ë°©ì•ˆ

{analysis_summary['improvement_suggestions']}

### 7.2 ì¥ê¸° ì—°êµ¬ ë°©í–¥

1. **ì ì‘ì  ì „ëµ ê°œë°œ**:
   - í”„ë¡œì íŠ¸ íŠ¹ì„±ê³¼ ì§„í–‰ ìƒí™©ì— ë”°ë¥¸ ë™ì  ì „ëµ ì „í™˜
   - ì‹¤ì‹œê°„ ì„±ê³¼ í”¼ë“œë°± ê¸°ë°˜ íƒìƒ‰ ê°•ë„ ìë™ ì¡°ì ˆ

2. **ë©€í‹° ëª©ì  ìµœì í™”**:
   - ê±´ì¶• ì„±ëŠ¥, ë¹„ìš©, ì‹œê³µì„±ì„ ë™ì‹œ ê³ ë ¤í•˜ëŠ” í†µí•© ë³´ìƒ í•¨ìˆ˜
   - íŒŒë ˆí†  ìµœì í•´ ì§‘í•© íƒìƒ‰ì„ ìœ„í•œ ë‹¤ëª©ì  ì•¡ì…˜ ì „ëµ

3. **ì „ì´ í•™ìŠµ ì ìš©**:
   - ìœ ì‚¬ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í™œìš©í•œ ì´ˆê¸° ì•¡ì…˜ ê°€ì¤‘ì¹˜ ì„¤ì •
   - ë„ë©”ì¸ ì§€ì‹ í†µí•©ì„ í†µí•œ íƒìƒ‰ íš¨ìœ¨ì„± í–¥ìƒ

4. **ì„¤ëª… ê°€ëŠ¥í•œ AI**:
   - ì•¡ì…˜ ì„ íƒ ê·¼ê±°ì˜ ì‹œê°í™” ë° í•´ì„
   - ì„¤ê³„ìê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ì•¡ì…˜ ì¶”ì²œ ì‹œìŠ¤í…œ

## 8. ê²°ë¡ 

### 8.1 ì „ëµë³„ ì„±ê³¼ ìš”ì•½

**{strategy_name_kr}ì˜ íŠ¹ì§•:**
- **íƒìƒ‰ íŠ¹ì„±**: {analysis_summary['exploration_analysis'].split('.')[0]}
- **ì•ˆì •ì„±**: {analysis_summary['correlation_analysis'].split('.')[0]}
- **ì„±ê³¼ ê¸°ì—¬ë„**: {analysis_summary['performance_analysis'].split('.')[0]}

### 8.2 ì‹¤ë¬´ ê¶Œì¥ì‚¬í•­

1. **í”„ë¡œì íŠ¸ ì´ˆê¸°**: ìš”êµ¬ì‚¬í•­ê³¼ ì œì•½ì¡°ê±´ì— ë”°ë¥¸ ì „ëµ ì„ íƒ
2. **í•™ìŠµ ê³¼ì •**: ì •ê¸°ì ì¸ ì„±ê³¼ ëª¨ë‹ˆí„°ë§ ë° ì „ëµ ì¡°ì •
3. **ê²°ê³¼ í™œìš©**: ì•¡ì…˜ íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ì„¤ê³„ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

### 8.3 ìµœì¢… í‰ê°€

ì´ ë¶„ì„ì„ í†µí•´ {strategy_name_kr}ì˜ ì•¡ì…˜ íƒìƒ‰ íŠ¹ì„±ê³¼ í•™ìŠµ íŒ¨í„´ì„ ì¢…í•©ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ê° ì „ëµì€ ê³ ìœ í•œ ì¥ë‹¨ì ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, í”„ë¡œì íŠ¸ì˜ ëª©í‘œì™€ ì œì•½ì¡°ê±´ì— ë”°ë¼ ì ì ˆí•œ ì „ëµì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

---

**ë¶„ì„ ì™„ë£Œ ì‹œê°„**: {timestamp}  
**ì‚¬ìš©ëœ ë°ì´í„°**: {analysis_summary['total_samples']:,}ê°œ ìƒ˜í”Œ  
**í•„í„°ë§ëœ ì´ˆê¸°í™” ì•¡ì…˜**: ë¡œê·¸ ì°¸ì¡°  
**ë¶„ì„ ë„êµ¬**: Python ê¸°ë°˜ ê°œì„ ëœ ì•¡ì…˜ ì¶”ì´ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ v2.0

---

## ë¶€ë¡

### A. ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

- **ë°ì´í„° ì „ì²˜ë¦¬**: ì´ˆê¸°í™” ì•¡ì…˜ ìë™ ê°ì§€ ë° ì œê±°
- **ì•„ì›ƒë¼ì´ì–´ ì²˜ë¦¬**: 99% ë¶„ìœ„ìˆ˜ ê¸°ì¤€ ê·¹ê°’ í•„í„°ë§
- **ìŠ¤ë¬´ë”© ê¸°ë²•**: ì ì‘ì  ì´ë™í‰ê·  (ìœˆë„ìš° í¬ê¸°: ë°ì´í„° í¬ê¸°ì˜ 5-10%)
- **ìƒê´€ê´€ê³„ ê³„ì‚°**: í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ë° ì´ë™ ìœˆë„ìš° ìƒê´€ê´€ê³„

### B. ì‹œê°í™” ë²”ë¡€

- **ì‹¤ì„ **: ìŠ¤ë¬´ë”©ëœ ì¶”ì´
- **ì ì„ **: ì •ê·œí™”ëœ ê°’ (-1~1 ë²”ìœ„)
- **ìŒì˜**: í•™ìŠµ ë‹¨ê³„ë³„ êµ¬ê°„
- **ìƒ‰ìƒ**: ì‹œê°„ ì§„í–‰ (ì–´ë‘ìš¸ìˆ˜ë¡ í›„ê¸°)

### C. ìš©ì–´ ì •ì˜

- **ë³€ë™ê³„ìˆ˜(CV)**: í‘œì¤€í¸ì°¨ë¥¼ í‰ê· ìœ¼ë¡œ ë‚˜ëˆˆ ê°’, ìƒëŒ€ì  ë³€ë™ì„± ì¸¡ì •
- **íƒìƒ‰ í™œë™ë„**: ì´ì „ ìŠ¤í… ëŒ€ë¹„ ì „ì²´ ì•¡ì…˜ ë³€í™”ëŸ‰ì˜ ì´ë™í‰ê· 
- **í•™ìŠµ ë‹¨ê³„**: ì „ì²´ í•™ìŠµ ê³¼ì •ì„ ì‹œê°„ìˆœìœ¼ë¡œ êµ¬ë¶„í•œ êµ¬ê°„
- **ì•¡ì…˜ ê³µê°„**: ëª¨ë“  ê°€ëŠ¥í•œ ì•¡ì…˜ ì¡°í•©ì´ ì´ë£¨ëŠ” ë‹¤ì°¨ì› ê³µê°„
"""